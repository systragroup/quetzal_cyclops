{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_folder': '../../scenarios/quebec', 'params': {'aggregation': {'distance': 1000}, 'constant': {'cst_incline': 1}, 'road_weight': {'residential': 0.5, 'secondary_link': 0.3, 'secondary': 0.3, 'tertiary': 0.3, 'cycleway': 1.1, 'primary': 0.3, 'motorway_link': 0, 'primary_link': 0.3, 'tertiary_link': 0.3, 'motorway': 0, 'trunk': 0.2, 'trunk_link': 0.2}, 'shared_cycleway_weight': {'residential': 0.8, 'secondary_link': 0.5, 'secondary': 0.5, 'tertiary': 0.5, 'cycleway': 1.1, 'primary': 0.5, 'motorway_link': 0, 'primary_link': 0.5, 'tertiary_link': 0.5, 'motorway': 0, 'trunk': 0.4, 'trunk_link': 0.4}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "aggregation = {'distance':1000}\n",
    "constant = {'cst_incline':1}\n",
    "road_weight = {'residential':0.5,\n",
    "            'secondary_link':0.3,\n",
    "            'secondary':0.3,\n",
    "            'tertiary':0.3,\n",
    "            'cycleway':1.1,\n",
    "            'primary':0.3,\n",
    "            'motorway_link':0,\n",
    "            'primary_link':0.3,\n",
    "            'tertiary_link':0.3,\n",
    "            'motorway':0,\n",
    "            'trunk':0.2, \n",
    "            'trunk_link':0.2  \n",
    "            }\n",
    "shared_cycleway_weight = {'residential':0.8,\n",
    "            'secondary_link':0.5,\n",
    "            'secondary':0.5,\n",
    "            'tertiary':0.5,\n",
    "            'cycleway':1.1,\n",
    "            'primary':0.5,\n",
    "            'motorway_link':0,\n",
    "            'primary_link':0.5,\n",
    "            'tertiary_link':0.5,\n",
    "            'motorway':0,\n",
    "            'trunk':0.4, \n",
    "            'trunk_link':0.4   \n",
    "        }\n",
    "\n",
    "params = {'aggregation':aggregation,'constant':constant, 'road_weight': road_weight, 'shared_cycleway_weight': shared_cycleway_weight}\n",
    "\n",
    "         \n",
    "\n",
    "default = {'training_folder': '../../scenarios/quebec', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736a20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "from quetzal.engine.road_model import RoadModel\n",
    "from quetzal.engine.pathfinder_utils import get_path, parallel_dijkstra, build_index, sparse_matrix\n",
    "from quetzal.engine.msa_utils import get_zone_index, assign_volume\n",
    "import numpy as np\n",
    "import random\n",
    "from shapely.geometry import Point\n",
    "from typing import Tuple\n",
    "num_cores = 1\n",
    "#from sklearn.cluster import KMeans\n",
    "from syspy.spatial.spatial import nearest, agglomerative_clustering, voronoi_diagram_dataframes\n",
    "from quetzal.engine.pathfinder_utils import simple_routing,get_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc057466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicated_links(links: gpd.GeoDataFrame,\n",
    "                          sort_column: str = 'maxspeed', \n",
    "                          ascending: bool = False, \n",
    "                          return_dropped:bool = False)-> Tuple[gpd.GeoDataFrame,list]:\n",
    "    '''\n",
    "    drop duplicated links (a,b) with condition sort_column. if maxspeed and ascending=False, keep faster road\n",
    "    '''\n",
    "    before = set(links.index)\n",
    "    links['dup'] = links['a'] + links['b']\n",
    "    links = links.sort_values(sort_column, ascending=ascending).drop_duplicates('dup').sort_index()\n",
    "    links = links.drop(columns='dup')\n",
    "    after = set(links.index)\n",
    "    diff = list(before-after)\n",
    "    print(len(diff), 'links dropped')\n",
    "    return links, diff\n",
    "\n",
    "def get_epsg(lat: float, lon: float) -> int:\n",
    "    '''\n",
    "    return EPSG in meter for a given (lat,lon)\n",
    "    lat is north south \n",
    "    lon is est west\n",
    "    '''\n",
    "    return int(32700 - round((45 + lat) / 90, 0) * 100 + round((183 + lon) / 6, 0))\n",
    "\n",
    "def zones_nearest_node(zones,nodes,drop_duplicates=False):\n",
    "    # getting zones centroids\n",
    "    centroid = zones.copy()\n",
    "    centroid['geometry'] = centroid.centroid\n",
    "    # finding nearest node\n",
    "    neigh = nearest(centroid, nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    centroid['node_index'] = centroid.index.map(zone_node_dict.get)\n",
    "    print('max_distance found: ', neigh['distance'].max())\n",
    "    # check for duplicated nodes. if there is. drop the duplicated zones.\n",
    "    if drop_duplicates:\n",
    "        if len(centroid.drop_duplicates('node_index')) != len(centroid):\n",
    "            print('there is zones associates to the same road_node')\n",
    "            # duplicated = centroid[centroid['node_index'].duplicated()]['node_index'].values\n",
    "            print('dropping zones: ')\n",
    "            print(centroid[centroid['node_index'].duplicated()].index.values)\n",
    "            centroid = centroid.drop_duplicates('node_index')\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e405b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../scenarios/quebec/inputs/road/\n"
     ]
    }
   ],
   "source": [
    "base_folder = argv['training_folder']\n",
    "road_folder = base_folder + '/inputs/road/'\n",
    "demand_folder = base_folder +'/inputs/'\n",
    "output_folder = base_folder +'/outputs/'\n",
    "print(road_folder)\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd032bd",
   "metadata": {},
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dadadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_incline = argv['params' ]['constant']['cst_incline']\n",
    "cst_road = argv['params']['road_weight']\n",
    "cst_shared = argv['params']['shared_cycleway_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfcf01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure its float\n",
    "cst_incline = float(cst_incline)\n",
    "cst_road = {k:float(v) for k,v in cst_road.items()}\n",
    "cst_shared = {k:float(v) for k,v in cst_shared.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c61586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a674100",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(road_folder + 'road_links.geojson') \n",
    "nodes = gpd.read_file(road_folder + 'road_nodes.geojson')\n",
    "links = links.set_index('index')\n",
    "nodes = nodes.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5c4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv(demand_folder+'demand.csv')\n",
    "demand = demand.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1089d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8e8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_test = pd.read_csv(demand_folder + 'od_test.csv')\n",
    "od_test = od_test.set_index('index')\n",
    "assert all([col in od_test.columns for col in ['name','xo','yo','xd','yd'] ]), 'need name, xo, yo, xd, yd in od_test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c1e873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([col in demand.columns for col in ['xo','yo','xd','yd','volume'] ]), 'need origin,destination and volume in demand'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a78e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae98c0d",
   "metadata": {},
   "source": [
    "# agg demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0114af",
   "metadata": {},
   "source": [
    "format demand and create zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda2a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['origin'] = [*zip(demand['xo'],demand['yo'])]\n",
    "demand['destination'] = [*zip(demand['xd'],demand['yd'])]\n",
    "demand = demand.drop(columns=['xo','yo','xd','yd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3167612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique zones\n",
    "zones_set = set(demand['origin'].values).union(set(demand['destination'].values))\n",
    "zones_dict = {val:'zone_'+str(i) for i,val in enumerate(zones_set)}\n",
    "zones_df = [{'index':zone,'geometry':Point(val)} for val,zone in zones_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0743f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['origin'] = demand['origin'].apply(lambda x: zones_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: zones_dict.get(x))\n",
    "zones = gpd.GeoDataFrame(zones_df,crs=4326).set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d893c7",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da3d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dist = float(argv['params']['aggregation']['distance'])\n",
    "epsg = get_epsg(zones.iloc[0]['geometry'].y, zones.iloc[0]['geometry'].x)\n",
    "label = agglomerative_clustering(zones.to_crs(epsg), distance_threshold = agg_dist)\n",
    "zones['cluster'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13678e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 zones agg to 626  zones\n"
     ]
    }
   ],
   "source": [
    "print(len(zones),'zones agg to',len(zones['cluster'].unique()),' zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "860b21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict zone:cluster\n",
    "zones['cluster'] = 'zone_' + zones['cluster'].astype(str)\n",
    "cluster_dict = zones['cluster'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45c23c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated cluster and rename index with new cluster as zones_id\n",
    "zones = zones.drop_duplicates('cluster')\n",
    "zones = zones.set_index('cluster')\n",
    "zones.index.name='index'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a9a81",
   "metadata": {},
   "source": [
    " AGG demand on new zones (volime is sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3b30dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply new cluster fict to the demand\n",
    "demand['origin'] = demand['origin'].apply(lambda x: cluster_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: cluster_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98c67504",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = demand.groupby(['origin','destination']).agg(sum).reset_index()\n",
    "demand.index.name = 'index'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af382408",
   "metadata": {},
   "source": [
    "# export zones and demand in outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76782b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zones.to_file(output_folder + 'centroids.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ee682fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by \"origin\" and \"destination\", and then convert to JSON\n",
    "grouped = demand.groupby([\"origin\", \"destination\"])[\"volume\"].sum().reset_index()\n",
    "json_data = {}\n",
    "for _, row in grouped.iterrows():\n",
    "    origin = row[\"origin\"]\n",
    "    destination = row[\"destination\"]\n",
    "    volume = row[\"volume\"]\n",
    "    if origin not in json_data:\n",
    "        json_data[origin] = {}\n",
    "    json_data[origin][destination] = volume\n",
    "\n",
    "    \n",
    "with open(output_folder + 'zones.json', 'w') as json_file:\n",
    "    json.dump({'volume':json_data},json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c13e64b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boivin/.pyenv/versions/3.8.6/envs/quetzal_env/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "convex_hull = zones.unary_union.convex_hull.buffer(1e-3)\n",
    "voronoi = voronoi_diagram_dataframes(zones['geometry'])\n",
    "voronoi = gpd.GeoDataFrame(voronoi[0],crs=4326)\n",
    "voronoi = voronoi.clip(convex_hull)\n",
    "voronoi.to_file(output_folder + 'zones.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62d21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c6767e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef create_zones_from_nodes(nodes,num_zones=200):\\n    nodes['x'] = nodes['geometry'].apply(lambda p:p.x)\\n    nodes['y'] = nodes['geometry'].apply(lambda p:p.y)\\n    cluster = KMeans(n_clusters=num_zones,random_state=0,n_init='auto')\\n    cluster.fit(nodes[['x','y']].values)\\n    geom = [Point(val) for val in cluster.cluster_centers_]\\n    zones = gpd.GeoDataFrame(range(len(geom)),geometry=geom,crs=4326).drop(columns=0)\\n    zones.index = 'zone_' + zones.index.astype(str)\\n    return zones\\n#create_zones_from_nodes(zones).plot()\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_zones_from_nodes(nodes,num_zones=200):\n",
    "    nodes['x'] = nodes['geometry'].apply(lambda p:p.x)\n",
    "    nodes['y'] = nodes['geometry'].apply(lambda p:p.y)\n",
    "    cluster = KMeans(n_clusters=num_zones,random_state=0,n_init='auto')\n",
    "    cluster.fit(nodes[['x','y']].values)\n",
    "    geom = [Point(val) for val in cluster.cluster_centers_]\n",
    "    zones = gpd.GeoDataFrame(range(len(geom)),geometry=geom,crs=4326).drop(columns=0)\n",
    "    zones.index = 'zone_' + zones.index.astype(str)\n",
    "    return zones\n",
    "#create_zones_from_nodes(zones).plot()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82be5c4",
   "metadata": {},
   "source": [
    "# split oneway quenedi links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d8298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "972d8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split quenedi road links\n",
    "self = RoadModel(links,nodes,zones,ff_time_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae842aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split rlinks to oneways\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('split rlinks to oneways')\n",
    "self.split_quenedi_rlinks()\n",
    "#self.zones_nearest_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa789405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bcc60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zones = self.zones_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e64b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = self.road_links\n",
    "del self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ffc54",
   "metadata": {},
   "source": [
    "# tag cycleways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "245dae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = [idx for idx in links.index if not idx.endswith('_r')]\n",
    "index_r = [idx for idx in links.index if idx.endswith('_r')]\n",
    "assert len(index)+len(index_r) == len(links)\n",
    "\n",
    "links['isroad'] = True\n",
    "ls = links.loc[index].loc[links['cycleway'].isin(['yes','shared'])].index\n",
    "links.loc[ls,'isroad'] = False\n",
    "ls = links.loc[index_r].loc[links['cycleway_reverse'].isin(['yes','shared'])].index\n",
    "links.loc[ls,'isroad'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cd0830f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3172"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links[~links['isroad']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588921e",
   "metadata": {},
   "source": [
    "# apply Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be57ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['incline'] = links['incline'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a86d178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incline weigth (starting point)\n",
    "links['eff_speed'] = 20  * (1 - cst_incline * np.sin(np.deg2rad(links['incline'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93500c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derate it with road weight\n",
    "links['cst_road'] = links['highway'].apply(lambda x: cst_road.get(x,1))\n",
    "links.loc[links['isroad'],'eff_speed'] = links.loc[links['isroad'],'eff_speed'] * links.loc[links['isroad'],'cst_road']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19f9e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derate it with shared cycleway weight\n",
    "links['cst_shared'] = links['highway'].apply(lambda x: cst_shared.get(x,1))\n",
    "\n",
    "ls = links.loc[index].loc[links['cycleway']=='shared'].index\n",
    "links.loc[ls,'eff_speed'] = links.loc[ls,'eff_speed'] * links.loc[ls,'cst_shared']\n",
    "\n",
    "ls = links.loc[index_r].loc[links['cycleway_reverse']=='shared'].index\n",
    "links.loc[ls,'eff_speed'] = links.loc[ls,'eff_speed'] * links.loc[ls,'cst_shared']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b554b1c",
   "metadata": {},
   "source": [
    "transform effective speed to a weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e65c1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anything with neg speed round to 0. (dijkstra need positive weight)\n",
    "links['eff_speed'] = links['eff_speed'].apply(lambda x : max(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb4e8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['weight'] = links['length']/(links['eff_speed']*1000/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2e71f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.drop(columns=['cst_road','cst_shared'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06600d",
   "metadata": {},
   "source": [
    "# zone to nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6411e",
   "metadata": {},
   "source": [
    "get the list of nodes with weight != inf. we do not want to route from or to nodes that are not cycle (ex motorway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35217581",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlinks = links[np.isfinite(links['weight'])][['a','b']]\n",
    "nodes_set = set(tlinks['a']).union(set(tlinks['b']))\n",
    "possible_nodes = nodes.loc[list(nodes_set)].sort_index()\n",
    "del tlinks,nodes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88437f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_417073/3645094334.py:28: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid['geometry'] = centroid.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_distance found:  0.022534254147859218\n"
     ]
    }
   ],
   "source": [
    "zones = zones_nearest_node(zones, possible_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb00df2",
   "metadata": {},
   "source": [
    "# Shortest path + volume assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65a754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b51bbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_nodes_dict = zones['node_index'].to_dict()\n",
    "demand['o_zone'] = demand['origin']\n",
    "demand['d_zone'] = demand['destination']\n",
    "demand['origin'] = demand['origin'].apply(lambda x: zones_nodes_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: zones_nodes_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5274234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47785fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = links[['a', 'b','weight']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea0b18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 links dropped\n"
     ]
    }
   ],
   "source": [
    "df, dropped = drop_duplicated_links(df,sort_column='weight',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f43aecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df[['a', 'b', 'weight']].values  # to build the index once and for all\n",
    "index = build_index(edges)\n",
    "reversed_index = {v: k for k, v in index.items()}\n",
    "# apply sparse index on zones\n",
    "demand, zones_indices = get_zone_index(df, demand, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "484da8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sparse index on links\n",
    "df['sparse_a'] = df['a'].apply(lambda x: index.get(x))\n",
    "df['sparse_b'] = df['b'].apply(lambda x: index.get(x))\n",
    "volumes_sparse_keys = list(zip(df['sparse_a'],df['sparse_b']))\n",
    "\n",
    "odv = demand[['o', 'd', 'volume']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf84a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df[['a', 'b', 'weight']].values\n",
    "sparse, _ = sparse_matrix(edges, index=index)\n",
    "time_matrix, predecessors = parallel_dijkstra(sparse,\n",
    "                                              directed=True,\n",
    "                                              indices=zones_indices,\n",
    "                                              return_predecessors=True,\n",
    "                                              num_core=num_cores,\n",
    "                                              keep_running=True)\n",
    "\n",
    "# this give OD_time/time_matrix on each links. then X links time for the ratio links_time/tot_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e40870a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_volumes = assign_volume(odv,predecessors,volumes_sparse_keys,reversed_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f67f3",
   "metadata": {},
   "source": [
    "restrict links to df.index (dropped duplicated links). if not. volume will not be assign on the right link (when duplicated) or, maybe on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b36fde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['volume'] = 0\n",
    "links.loc[df.index,'volume'] = links.loc[df.index].set_index(['a', 'b']).index.map(ab_volumes.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df39ff5",
   "metadata": {},
   "source": [
    "# cleaning and exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9e6cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_r = [col for col in links.columns if col.endswith('_r')]\n",
    "links = links.drop(columns=col_r)\n",
    "links = links.drop(columns=['isroad'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94c53d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.to_file(output_folder + 'loaded_links.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70c98fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25806809"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['volume'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f08d87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.75749731063843\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d89d07f",
   "metadata": {},
   "source": [
    "# OD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adcdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89facb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boivin/.pyenv/versions/3.8.6/envs/quetzal_env/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n",
      "/home/boivin/.pyenv/versions/3.8.6/envs/quetzal_env/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "od_test['geometry_o'] = [Point(val) for val in od_test[['xo','yo']].values]\n",
    "od_test['geometry_d'] = [Point(val) for val in od_test[['xd','yd']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b70a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nearest node with KNN. nodes are now the origin and destination.\n",
    "od_test['geometry'] = od_test['geometry_o']\n",
    "neigh = nearest(od_test, possible_nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "od_test['origin'] = od_test.index.map(zone_node_dict.get)\n",
    "\n",
    "od_test['geometry'] = od_test['geometry_d']\n",
    "neigh = nearest(od_test, nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "od_test['destination'] = od_test.index.map(zone_node_dict.get)\n",
    "\n",
    "od_test = od_test.drop(columns=['xo','xd','yo','yd','geometry_o','geometry_d','geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b004c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_nodes = od_test['origin'].values\n",
    "d_nodes = od_test['destination'].values\n",
    "\n",
    "time_mat, predecessors, node_index = simple_routing(o_nodes,d_nodes,links,weight_col='weight',return_predecessors=True)\n",
    "reversed_index = {v: k for k, v in node_index.items()}\n",
    "\n",
    "routes = gpd.GeoDataFrame()\n",
    "for o,d in  enumerate(od_test['destination'].values):\n",
    "    path = get_path(predecessors, o, node_index[d])\n",
    "    path = list(zip(path[:-1], path[1:]))\n",
    "\n",
    "    path = [(reversed_index[k[0]], reversed_index[k[1]]) for k in path]\n",
    "    links_dict = links.reset_index().set_index(['a','b'])['index'].to_dict()\n",
    "    path = [*map(links_dict.get,path)]\n",
    "\n",
    "    route = links.loc[path]\n",
    "    route['od_name'] =  od_test.iloc[o]['name']\n",
    "    routes = pd.concat([routes,route])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8985ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes.to_file(output_folder + 'od_routes.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "560f8f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.30944323539734\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "945c9663",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6522ef",
   "metadata": {},
   "source": [
    "# merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "228b5931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef merge_quenedi_rlinks(road_links,new_col):\\n    if 'oneway' not in road_links.columns:\\n        print('no column oneway. do not merge')\\n        return\\n    #get reversed links\\n    index_r = [idx for idx in road_links.index if idx.endswith('_r')]\\n    if len(index_r) == 0:\\n        print('all oneway, nothing to merge')\\n        return\\n    links_r = road_links.loc[index_r].copy()\\n    # create new reversed column with here speed and time\\n    links_r[new_col + '_r'] = links_r[new_col]\\n    # reindex with initial non _r index to merge\\n    links_r.index = links_r.index.map(lambda x: x[:-2])\\n    links_r = links_r[[new_col + '_r']]\\n    # drop added _r links, merge new here columns to inital two way links.\\n    road_links = road_links.drop(index_r, axis=0)\\n    # drop column if they exist before merge. dont want duplicates\\n    if new_col + '_r' in road_links.columns:\\n        road_links = road_links.drop(columns=new_col + '_r')\\n    road_links = pd.merge(road_links, links_r, left_index=True, right_index\\n                                =True, how='left')\\n    return road_links\\n\""
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def merge_quenedi_rlinks(road_links,new_col):\n",
    "    if 'oneway' not in road_links.columns:\n",
    "        print('no column oneway. do not merge')\n",
    "        return\n",
    "    #get reversed links\n",
    "    index_r = [idx for idx in road_links.index if idx.endswith('_r')]\n",
    "    if len(index_r) == 0:\n",
    "        print('all oneway, nothing to merge')\n",
    "        return\n",
    "    links_r = road_links.loc[index_r].copy()\n",
    "    # create new reversed column with here speed and time\n",
    "    links_r[new_col + '_r'] = links_r[new_col]\n",
    "    # reindex with initial non _r index to merge\n",
    "    links_r.index = links_r.index.map(lambda x: x[:-2])\n",
    "    links_r = links_r[[new_col + '_r']]\n",
    "    # drop added _r links, merge new here columns to inital two way links.\n",
    "    road_links = road_links.drop(index_r, axis=0)\n",
    "    # drop column if they exist before merge. dont want duplicates\n",
    "    if new_col + '_r' in road_links.columns:\n",
    "        road_links = road_links.drop(columns=new_col + '_r')\n",
    "    road_links = pd.merge(road_links, links_r, left_index=True, right_index\n",
    "                                =True, how='left')\n",
    "    return road_links\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "76aa32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links = merge_quenedi_rlinks(links,'volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5cb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11dfe2fb",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97918747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8adbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38ba7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
