{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_folder': '../../scenarios/NTA Dublin M50', 'params': {'aggregation': {'distance': 1000}, 'constant': {'cst_incline': 1}, 'cycleway_weight': {'Advisory bike lane': 1, 'Advisory bike lane (single side)': 1, 'Bicyclists dismount': 0.2, 'Bus lane with cycling allowed': 0.8, 'Buffered bike lane (road-side)': 0.9, 'Buffered bike lane (kerb-side)': 0.9, 'Buffered bike lane (both sides)': 0.9, 'Dedicated bike path': 1, 'Dedicated oneway bike path': 1, 'Future cycleway': 0, 'Future link': 0, 'Painted bike lane': 0.8, 'Peak hour bike lane': 1, 'Pedestrian path/street with cycling allowed': 0.9, 'Possible cycling infrastructure/link': 0.5, 'Protected bike lane': 1, 'Shared bike path': 0.6, 'Shared zone': 0.6, 'Sharrow': 0.5, 'Shoulder cyclable': 0.8}, 'road_weight': {'residential': 0.5, 'secondary_link': 0.3, 'secondary': 0.3, 'tertiary': 0.3, 'cycleway': 1.1, 'primary': 0.3, 'motorway_link': 0, 'primary_link': 0.3, 'tertiary_link': 0.3, 'motorway': 0, 'trunk': 0.2, 'trunk_link': 0.2}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "aggregation = {'distance':1000}\n",
    "constant = {'cst_incline':1}\n",
    "cycleway_weight = {\"Advisory bike lane\": 1,\n",
    "         \"Advisory bike lane (single side)\": 1,\n",
    "         \"Bicyclists dismount\": 0.2,\n",
    "         \"Bus lane with cycling allowed\": 0.8,\n",
    "         \"Buffered bike lane (road-side)\": 0.9,\n",
    "         \"Buffered bike lane (kerb-side)\": 0.9,\n",
    "         \"Buffered bike lane (both sides)\": 0.9,\n",
    "         \"Dedicated bike path\": 1,\n",
    "         \"Dedicated oneway bike path\": 1,\n",
    "         \"Future cycleway\": 0,\n",
    "         \"Future link\": 0,\n",
    "         \"Painted bike lane\": 0.8,\n",
    "         \"Peak hour bike lane\": 1,\n",
    "         \"Pedestrian path/street with cycling allowed\": 0.9,\n",
    "         \"Possible cycling infrastructure/link\": 0.5,\n",
    "         \"Protected bike lane\": 1,\n",
    "         \"Shared bike path\": 0.6,\n",
    "         \"Shared zone\": 0.6,\n",
    "         \"Sharrow\": 0.5,\n",
    "         \"Shoulder cyclable\": 0.8\n",
    "        }\n",
    "road_weight = {'residential':0.5,\n",
    "            'secondary_link':0.3,\n",
    "            'secondary':0.3,\n",
    "            'tertiary':0.3,\n",
    "            'cycleway':1.1,\n",
    "            'primary':0.3,\n",
    "            'motorway_link':0,\n",
    "            'primary_link':0.3,\n",
    "            'tertiary_link':0.3,\n",
    "            'motorway':0,\n",
    "            'trunk':0.2, \n",
    "            'trunk_link':0.2  \n",
    "            }\n",
    "\n",
    "params = {'aggregation':aggregation,'constant':constant, 'cycleway_weight': cycleway_weight, 'road_weight': road_weight}\n",
    "\n",
    "         \n",
    "\n",
    "default = {'training_folder': '../../scenarios/NTA Dublin M50', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "from quetzal.engine.road_model import RoadModel, _reverse_geom\n",
    "from quetzal.engine.pathfinder_utils import get_path, parallel_dijkstra, build_index, sparse_matrix\n",
    "from quetzal.engine.msa_utils import get_zone_index, assign_volume\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from typing import Tuple\n",
    "from geopy.distance import geodesic  # works for geopy version >=2\n",
    "#from sklearn.cluster import KMeans\n",
    "from syspy.spatial.spatial import nearest, agglomerative_clustering, voronoi_diagram_dataframes, add_geometry_coordinates\n",
    "from quetzal.engine.pathfinder_utils import simple_routing,get_path\n",
    "num_cores = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc057466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicated_links(links: gpd.GeoDataFrame,\n",
    "                          sort_column: str = 'maxspeed', \n",
    "                          ascending: bool = False, \n",
    "                          return_dropped:bool = False)-> Tuple[gpd.GeoDataFrame,list]:\n",
    "    '''\n",
    "    drop duplicated links (a,b) with condition sort_column. if maxspeed and ascending=False, keep faster road\n",
    "    '''\n",
    "    before = set(links.index)\n",
    "    links['dup'] = links['a'] + links['b']\n",
    "    links = links.sort_values(sort_column, ascending=ascending).drop_duplicates('dup').sort_index()\n",
    "    links = links.drop(columns='dup')\n",
    "    after = set(links.index)\n",
    "    diff = list(before-after)\n",
    "    print(len(diff), 'links dropped')\n",
    "    return links, diff\n",
    "\n",
    "def get_epsg(lat: float, lon: float) -> int:\n",
    "    '''\n",
    "    return EPSG in meter for a given (lat,lon)\n",
    "    lat is north south \n",
    "    lon is est west\n",
    "    '''\n",
    "    return int(32700 - round((45 + lat) / 90, 0) * 100 + round((183 + lon) / 6, 0))\n",
    "\n",
    "def zones_nearest_node(zones,nodes,drop_duplicates=False):\n",
    "    # getting zones centroids\n",
    "    centroid = zones.copy()\n",
    "    centroid['geometry'] = centroid.centroid\n",
    "    # finding nearest node\n",
    "    neigh = nearest(centroid, nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    centroid['node_index'] = centroid.index.map(zone_node_dict.get)\n",
    "    print('max_distance found: ', neigh['distance'].max())\n",
    "    # check for duplicated nodes. if there is. drop the duplicated zones.\n",
    "    if drop_duplicates:\n",
    "        if len(centroid.drop_duplicates('node_index')) != len(centroid):\n",
    "            print('there is zones associates to the same road_node')\n",
    "            # duplicated = centroid[centroid['node_index'].duplicated()]['node_index'].values\n",
    "            print('dropping zones: ')\n",
    "            print(centroid[centroid['node_index'].duplicated()].index.values)\n",
    "            centroid = centroid.drop_duplicates('node_index')\n",
    "    return centroid\n",
    "\n",
    "def get_flight_distance(x):\n",
    "    # inputs : [(lat,lon), (lat,lon)]. or [(y,x),(y,x)]\n",
    "    # however. geodesic use lon,lat. so its inverted here\n",
    "\n",
    "    \n",
    "    return geodesic(x[0], x[1]).m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb087e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization.py\n",
    "import six\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rounding(x):\n",
    "    if type(x)==str:\n",
    "        return x\n",
    "    elif x<10:\n",
    "        return float(np.round(x,2))\n",
    "    elif x<100:\n",
    "        return float(np.round(x,1))\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def put_units_in_row(df):\n",
    "    df = df.applymap(rounding, na_action='ignore')\n",
    "    index = df.index.values\n",
    "    df.loc['units'] = [col.split(' ')[1] for col in df.columns]\n",
    "    df.columns = [col.split(' ')[0] for col in df.columns]\n",
    "    index = np.insert(index,0,'units')\n",
    "    df = df.loc[index]\n",
    "    return df\n",
    "\n",
    "def normalize(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode().replace(' ', '_').lower().replace(',', '')\n",
    "\n",
    "class Current:\n",
    "    def __init__(self):\n",
    "        self.s = ''\n",
    "        \n",
    "    def replace_seen(self, s):\n",
    "        if self.s == s:\n",
    "            to_return = ''\n",
    "        else :\n",
    "            to_return = s \n",
    "        self.s = s\n",
    "        return to_return\n",
    "\n",
    "def label_index(data):\n",
    "    ix_name = data.index.name\n",
    "    c_name = data.columns.name \n",
    "    t = data.copy()\n",
    "    if c_name is not None:\n",
    "        t.index.name = c_name\n",
    "    if ix_name is not None:\n",
    "        ix = list(data.index)\n",
    "        t = t.reindex([ix_name] + list(ix))\n",
    "        t = t.fillna('')\n",
    "    return t\n",
    "\n",
    "def render_mpl_table(\n",
    "    data, \n",
    "    col_width=3.0, \n",
    "    row_height=0.625, \n",
    "    font_size=14,\n",
    "    header_size=14,\n",
    "    index_width_ratio=2,\n",
    "    header_color='#9d1a1e', \n",
    "    header_font_color = 'w',\n",
    "    sub_header_color='#d22328',\n",
    "    row_colors=['#f1f1f2', 'w'], \n",
    "    edge_color='w',\n",
    "    index_edge_color='#9d1a1e',\n",
    "    bbox=[0, 0, 1, 1], \n",
    "    header_columns=0,\n",
    "    figsize=None,\n",
    "    ax=None, \n",
    "    dpi=96,\n",
    "    **kwargs\n",
    "):\n",
    "    #c_levels = len(data.columns.names)\n",
    "    #c_first = data.columns.names[0]\n",
    "    \n",
    "    \n",
    "    i_levels = len(data.index.names)\n",
    "    i_first = list(data.index.names)[0]\n",
    "\n",
    "    data = data.reset_index()\n",
    "    current = Current()\n",
    "    try:\n",
    "        data[i_first] = data[i_first].apply(lambda s: current.replace_seen(s))\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    if figsize:\n",
    "        col_width = figsize[0] / (len(data.T) + (index_width_ratio - 1))\n",
    "        row_height = figsize[1] / (len(data) +1)\n",
    "        \n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size, dpi=dpi)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    \n",
    "\n",
    "    mpl_table = ax.table(\n",
    "        cellText=data.values, \n",
    "        bbox=bbox, \n",
    "        colLabels=data.columns, \n",
    "        colWidths= [col_width * index_width_ratio ] + [col_width for c in data.columns[1:]],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "    for k, cell in  six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(index_edge_color)\n",
    "        if k[0] < 1 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color=header_font_color)\n",
    "\n",
    "            cell.set_text_props( color=header_font_color)\n",
    "            cell.set_fontsize(header_size)\n",
    "            cell.set_facecolor(header_color)\n",
    "\n",
    "        elif k[1] < i_levels:\n",
    "            cell.set_text_props(weight='bold', color=header_font_color)\n",
    "            cell.set_text_props( color=header_font_color)\n",
    "            cell.set_fontsize(header_size)\n",
    "            cell.set_facecolor(sub_header_color)\n",
    "        else:\n",
    "            cell.set_edgecolor(edge_color)\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e405b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../scenarios/NTA Dublin M50/inputs/road/\n"
     ]
    }
   ],
   "source": [
    "base_folder = argv['training_folder']\n",
    "road_folder = base_folder + '/inputs/road/'\n",
    "demand_folder = base_folder +'/inputs/'\n",
    "od_folder = base_folder + '/inputs/od/'\n",
    "output_folder = base_folder +'/outputs/'\n",
    "print(road_folder)\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd032bd",
   "metadata": {},
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7dadadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_incline = argv['params' ]['constant']['cst_incline']\n",
    "cst_road = argv['params']['road_weight']\n",
    "cst_road = {k:float(v) for k,v in cst_road.items()}\n",
    "cst_cycleway = argv['params']['cycleway_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfcf01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure its float\n",
    "cst_incline = float(cst_incline)\n",
    "cst_cycleway = {k:float(v) for k,v in cst_cycleway.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b20ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a674100",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(road_folder + 'road_links.geojson') \n",
    "nodes = gpd.read_file(road_folder + 'road_nodes.geojson')\n",
    "links = links.set_index('index')\n",
    "nodes = nodes.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a20e960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepath(path,filename):\n",
    "    '''\n",
    "    get filePath cas insensitive (ex: read demand.csv but file is name DEMAND.csv)\n",
    "    path:'path/ ex: '../../scenarios/base/inputs/'\n",
    "    filename: ex: demand.csv\n",
    "    '''\n",
    "    files = os.listdir(demand_folder)\n",
    "    file = [file for file in files if filename.lower() == file.lower()]\n",
    "    if len(file)==0:\n",
    "        raise Exception(f'{path+filename} does not exist')\n",
    "    return path+file[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8c5c4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv(get_filepath(demand_folder ,'demand.csv'))\n",
    "assert all([col in demand.columns for col in ['lon_ori','lat_ori','lon_des','lat_des','volume'] ]), 'need lon_ori, lat_ori, lon_des, lat_des, volume in demand'\n",
    "demand = demand[['lon_ori','lat_ori','lon_des','lat_des','volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a66bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c9feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6071cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_file = od_folder + 'od.geojson'\n",
    "od_file_provided = os.path.isfile(od_file)\n",
    "if od_file_provided:\n",
    "    od_test = gpd.read_file(od_folder + 'od.geojson')\n",
    "    if 'name' not in od_test.columns:\n",
    "        od_test['name'] = od_test['index']\n",
    "    od_test['name'] = od_test['name'].fillna(od_test['index'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e31338",
   "metadata": {},
   "source": [
    "# agg demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fe77d",
   "metadata": {},
   "source": [
    "format demand and create zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "91e83de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Demand Aggregation ***\n"
     ]
    }
   ],
   "source": [
    "print('*** Demand Aggregation ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "10b25b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['origin'] = [*zip(demand['lon_ori'],demand['lat_ori'])]\n",
    "demand['destination'] = [*zip(demand['lon_des'],demand['lat_des'])]\n",
    "demand = demand.drop(columns=['lat_ori','lon_ori','lat_des','lon_des'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "df1b6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique zones\n",
    "zones_set = set(demand['origin'].values).union(set(demand['destination'].values))\n",
    "zones_dict = {val:'zone_'+str(i) for i,val in enumerate(zones_set)}\n",
    "zones_df = [{'index':zone,'geometry':Point(val)} for val,zone in zones_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0c2b545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['origin'] = demand['origin'].apply(lambda x: zones_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: zones_dict.get(x))\n",
    "zones = gpd.GeoDataFrame(zones_df,crs=4326).set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cddac1",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4de080e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dist = float(argv['params']['aggregation']['distance'])\n",
    "epsg = get_epsg(zones.iloc[0]['geometry'].y, zones.iloc[0]['geometry'].x)\n",
    "label = agglomerative_clustering(zones.to_crs(epsg), distance_threshold = agg_dist)\n",
    "zones['cluster'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dca17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "efda77a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163 zones agg to 434  zones\n"
     ]
    }
   ],
   "source": [
    "print(len(zones),'zones agg to',len(zones['cluster'].unique()),' zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6c6f92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict zone:cluster\n",
    "zones['cluster'] = 'zone_' + zones['cluster'].astype(str)\n",
    "cluster_dict = zones['cluster'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9191a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated cluster and rename index with new cluster as zones_id\n",
    "zones = zones.drop_duplicates('cluster')\n",
    "zones = zones.set_index('cluster')\n",
    "zones.index.name='index'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d3cdc",
   "metadata": {},
   "source": [
    " AGG demand on new zones (volime is sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "677503c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply new cluster fict to the demand\n",
    "demand['origin'] = demand['origin'].apply(lambda x: cluster_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: cluster_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a95b25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = demand.groupby(['origin','destination']).agg(sum).reset_index()\n",
    "demand.index.name = 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c692d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18fa6f20",
   "metadata": {},
   "source": [
    "# export zones and demand in outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "de2a4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating and exporting zones ***\n"
     ]
    }
   ],
   "source": [
    "#zones.to_file(output_folder + 'centroids.geojson',driver='GeoJSON')\n",
    "print('*** Creating and exporting zones ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9bcea6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by \"origin\" and \"destination\", and then convert to JSON\n",
    "grouped = demand.groupby([\"origin\", \"destination\"])[\"volume\"].sum().reset_index()\n",
    "json_data = {}\n",
    "data = {}\n",
    "for _, row in grouped.iterrows():\n",
    "    origin = row[\"origin\"]\n",
    "    destination = row[\"destination\"]\n",
    "    volume = row[\"volume\"]\n",
    "    if origin not in data:\n",
    "        data[origin] = {}\n",
    "    data[origin][destination] = volume\n",
    "\n",
    "    \n",
    "json_data['outgoing volume'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ef791144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by \"origin\" and \"destination\", and then convert to JSON\n",
    "grouped = demand.groupby([\"destination\", \"origin\"])[\"volume\"].sum().reset_index()\n",
    "data = {}\n",
    "for _, row in grouped.iterrows():\n",
    "    origin = row[\"origin\"]\n",
    "    destination = row[\"destination\"]\n",
    "    volume = row[\"volume\"]\n",
    "    if destination not in data:\n",
    "        data[destination] = {}\n",
    "    data[destination][origin] = volume\n",
    "\n",
    "json_data['ingoing volume'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "587c0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with open(output_folder + 'zones.json', 'w') as json_file:\n",
    "    json.dump(json_data,json_file)\n",
    "with open(output_folder + 'demand.json', 'w') as json_file:\n",
    "    json.dump(json_data,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e9ac4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "production = demand.groupby([\"origin\"])[\"volume\"].sum().to_dict()\n",
    "attraction = demand.groupby([\"destination\"])[\"volume\"].sum().to_dict()\n",
    "zones['production'] = zones.index.map(production.get)\n",
    "zones['attraction'] = zones.index.map(attraction.get)\n",
    "zones = zones.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0860bfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boivin/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "convex_hull = zones.unary_union.convex_hull.buffer(1e-3)\n",
    "voronoi = voronoi_diagram_dataframes(zones['geometry'])\n",
    "voronoi = gpd.GeoDataFrame(voronoi[0],crs=4326)\n",
    "voronoi = pd.merge(voronoi,zones[['production','attraction']],left_index=True,right_index=True)\n",
    "voronoi = voronoi.clip(convex_hull)\n",
    "voronoi.to_file(output_folder + 'zones.geojson',driver='GeoJSON')\n",
    "zones.to_file(output_folder + 'demand.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd6c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c7c6767e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef create_zones_from_nodes(nodes,num_zones=200):\\n    nodes['x'] = nodes['geometry'].apply(lambda p:p.x)\\n    nodes['y'] = nodes['geometry'].apply(lambda p:p.y)\\n    cluster = KMeans(n_clusters=num_zones,random_state=0,n_init='auto')\\n    cluster.fit(nodes[['x','y']].values)\\n    geom = [Point(val) for val in cluster.cluster_centers_]\\n    zones = gpd.GeoDataFrame(range(len(geom)),geometry=geom,crs=4326).drop(columns=0)\\n    zones.index = 'zone_' + zones.index.astype(str)\\n    return zones\\n#create_zones_from_nodes(zones).plot()\\n\""
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_zones_from_nodes(nodes,num_zones=200):\n",
    "    nodes['x'] = nodes['geometry'].apply(lambda p:p.x)\n",
    "    nodes['y'] = nodes['geometry'].apply(lambda p:p.y)\n",
    "    cluster = KMeans(n_clusters=num_zones,random_state=0,n_init='auto')\n",
    "    cluster.fit(nodes[['x','y']].values)\n",
    "    geom = [Point(val) for val in cluster.cluster_centers_]\n",
    "    zones = gpd.GeoDataFrame(range(len(geom)),geometry=geom,crs=4326).drop(columns=0)\n",
    "    zones.index = 'zone_' + zones.index.astype(str)\n",
    "    return zones\n",
    "#create_zones_from_nodes(zones).plot()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82be5c4",
   "metadata": {},
   "source": [
    "# split oneway quenedi links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e42ce6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Processing cycleways ***\n"
     ]
    }
   ],
   "source": [
    "print('*** Processing cycleways ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "972d8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split quenedi road links\n",
    "self = RoadModel(links,nodes,zones,ff_time_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ae842aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split rlinks to oneways\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('split rlinks to oneways')\n",
    "self.split_quenedi_rlinks()\n",
    "#self.zones_nearest_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0640913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = self.road_links\n",
    "del self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ffc54",
   "metadata": {},
   "source": [
    "# tag cycleways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a7c79545",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [idx for idx in links.index if not idx.endswith('_r')]\n",
    "index_r = [idx for idx in links.index if idx.endswith('_r')]\n",
    "assert len(index)+len(index_r) == len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7bd0df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted links cycleway is the reverse one\n",
    "links.loc[index_r,'cycleway'] = links.loc[index_r,'cycleway_reverse'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1035c",
   "metadata": {},
   "source": [
    "split oneway road with cycleway on both side or only in reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "245dae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_quenedi_cycleway(links, oneway='1',no_col='No'):\n",
    "    # add oneway links with cycleway_reverse as links. only the one with cycleway_reverse != No.\n",
    "    # so. you can cycle on oneway with no cycleway only in the oneway direction.\n",
    "    if 'oneway' not in links.columns:\n",
    "        print('no column oneway. do not split')\n",
    "        return\n",
    "    links_c = links[links['oneway']==oneway].copy()\n",
    "    if len(links_c) == 0:\n",
    "        print('all oneway, nothing to split')\n",
    "    \n",
    "    links_c = links_c[links_c['cycleway_reverse'] != no_col]\n",
    "    links_c['cycleway'] = links_c['cycleway_reverse']\n",
    "    links_c.index = links_c.index.astype(str) + '_c'\n",
    "    \n",
    "    # reverse links (a=>b, b=>a)\n",
    "    links_c = links_c.rename(columns={'a': 'b', 'b': 'a'})\n",
    "    links_c['geometry'] = links_c['geometry'].apply(lambda g: _reverse_geom(g))\n",
    "    links = pd.concat([links, links_c])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "15f5bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = split_quenedi_cycleway(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "45ea0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_c = [idx for idx in links.index if idx.endswith('_c')]\n",
    "assert len(index)+len(index_r)+len(index_c) == len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "030f8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = [col for col in links.columns if col.endswith('_r')]\n",
    "if 'cycleway_reverse' in links.columns:\n",
    "    r_cols = r_cols + ['cycleway_reverse']\n",
    "links = links.drop(columns=r_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88338a7e",
   "metadata": {},
   "source": [
    "# inclines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "534437c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['incline'] = links['incline'].astype(float)\n",
    "links['incline'] = links['incline'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5284d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse incline on reversed links\n",
    "links.loc[index_r,'incline'] = -links.loc[index_r,'incline']\n",
    "#create this column for vizualisation\n",
    "links['incline (abs)'] = abs(links['incline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0830f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5588921e",
   "metadata": {},
   "source": [
    "# apply Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e3281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a86d178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incline weigth (starting point)\n",
    "default_speed = 20 #kmh\n",
    "links['eff_speed'] = default_speed   * (1 - cst_incline * np.sin(np.deg2rad(links['incline'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "299c1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['cst_road'] = links['highway'].apply(lambda x: cst_road.get(x,1))\n",
    "links['cst_cycleway'] = links['cycleway'].apply(lambda x: cst_cycleway.get(x,np.nan))\n",
    "links['cst'] = links['cst_cycleway'].combine_first(links['cst_road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5567729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "93500c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derate it with cycleway\n",
    "links['eff_speed'] = links['eff_speed'] * links['cst']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b554b1c",
   "metadata": {},
   "source": [
    "transform effective speed to a weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e65c1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anything with neg speed round to 0. (dijkstra need positive weight)\n",
    "links['eff_speed'] = links['eff_speed'].apply(lambda x : max(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fb4e8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['weight'] = links['length']/(links['eff_speed']*1000/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b2e71f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.drop(columns=['cst_cycleway','cst_road','cst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac74cfc",
   "metadata": {},
   "source": [
    "# zone to nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfd282",
   "metadata": {},
   "source": [
    "get the list of nodes with weight != inf. we do not want to route from or to nodes that are not cycle (ex motorway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fac2aa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Zones to nodes ***\n"
     ]
    }
   ],
   "source": [
    "print('*** Zones to nodes ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9d23cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlinks = links[np.isfinite(links['weight'])][['a','b']]\n",
    "nodes_set = set(tlinks['a']).union(set(tlinks['b']))\n",
    "possible_nodes = nodes.loc[list(nodes_set)].sort_index()\n",
    "del tlinks,nodes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9d7f21c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273511/529603176.py:28: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid['geometry'] = centroid.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_distance found:  0.15572951404458735\n"
     ]
    }
   ],
   "source": [
    "zones = zones_nearest_node(zones, possible_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb00df2",
   "metadata": {},
   "source": [
    "# Shortest path + volume assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "91ece518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Assigning volume ***\n"
     ]
    }
   ],
   "source": [
    "print('*** Assigning volume ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b51bbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_nodes_dict = zones['node_index'].to_dict()\n",
    "demand['o_zone'] = demand['origin']\n",
    "demand['d_zone'] = demand['destination']\n",
    "demand['origin'] = demand['origin'].apply(lambda x: zones_nodes_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: zones_nodes_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "47785fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = links[['a', 'b','weight']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ea0b18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477 links dropped\n"
     ]
    }
   ],
   "source": [
    "df, dropped = drop_duplicated_links(df,sort_column='weight',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f43aecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df[['a', 'b', 'weight']].values  # to build the index once and for all\n",
    "index = build_index(edges)\n",
    "reversed_index = {v: k for k, v in index.items()}\n",
    "# apply sparse index on zones\n",
    "demand, zones_indices = get_zone_index(df, demand, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "484da8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sparse index on links\n",
    "df['sparse_a'] = df['a'].apply(lambda x: index.get(x))\n",
    "df['sparse_b'] = df['b'].apply(lambda x: index.get(x))\n",
    "volumes_sparse_keys = list(zip(df['sparse_a'],df['sparse_b']))\n",
    "\n",
    "odv = demand[['o', 'd', 'volume']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bf84a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df[['a', 'b', 'weight']].values\n",
    "sparse, _ = sparse_matrix(edges, index=index)\n",
    "time_matrix, predecessors = parallel_dijkstra(sparse,\n",
    "                                              directed=True,\n",
    "                                              indices=zones_indices,\n",
    "                                              return_predecessors=True,\n",
    "                                              num_core=num_cores,\n",
    "                                              keep_running=True)\n",
    "\n",
    "# this give OD_time/time_matrix on each links. then X links time for the ratio links_time/tot_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e40870a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_volumes = assign_volume(odv,predecessors,volumes_sparse_keys,reversed_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f67f3",
   "metadata": {},
   "source": [
    "restrict links to df.index (dropped duplicated links). if not. volume will not be assign on the right link (when duplicated) or, maybe on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b36fde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['volume'] = 0\n",
    "links.loc[df.index,'volume'] = links.loc[df.index].set_index(['a', 'b']).index.map(ab_volumes.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c28babea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#volume(1/eff_speed - 1/default_speed)\n",
    "links['time_loss'] = links['volume']* (1/links['eff_speed'] - 1/default_speed)\n",
    "links.loc[~np.isfinite(links['time_loss']),'time_loss'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852143c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f993c76",
   "metadata": {},
   "source": [
    "# exporting loaded Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4055d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Exporting loaded Links ***\n"
     ]
    }
   ],
   "source": [
    "print('*** Exporting loaded Links ***')\n",
    "links[['highway','cycleway', 'incline (abs)', 'eff_speed','weight','volume','time_loss','geometry']].to_file(output_folder + 'loaded_links.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08d87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5be1612",
   "metadata": {},
   "source": [
    "# Links Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9abea006",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_list=[]\n",
    "if 'selectLink' in links.columns:\n",
    "    links_list += list(links[links['selectLink']=='yes'].index)\n",
    "if 'selectLink_reverse' in links.columns:\n",
    "    links_list += list(links[links['selectLink_reverse']=='yes'].index)\n",
    "if len(links_list)>500:\n",
    "    print('too many selectLink. keep first 500.')\n",
    "    links_list = links_list[:500]\n",
    "    \n",
    "if len(links_list) > 0:\n",
    "    links_dict = links.reset_index().set_index(['a','b'])['index'].to_dict()\n",
    "    json_data={}\n",
    "    for link in links_list:\n",
    "        volumes={}\n",
    "        for o,d,v in odv:\n",
    "            path = get_path(predecessors,o,d)\n",
    "            path = [*map(reversed_index.get, path)]\n",
    "            path = list(zip(path[:-1], path[1:]))\n",
    "            path = [*map(links_dict.get,path)]\n",
    "            if link in path:\n",
    "                for key in path:\n",
    "                    try:\n",
    "                        volumes[key] += v\n",
    "                    except KeyError:\n",
    "                        volumes[key] = v\n",
    "        if len(volumes)>0:\n",
    "            json_data[link] = volumes\n",
    "\n",
    "\n",
    "    index_set=set()\n",
    "    for key,item in json_data.items():\n",
    "        index_set.update(item.keys())\n",
    "\n",
    "    route = links.loc[list(index_set)][['geometry']]\n",
    "    route.to_file(output_folder + 'selectLink.geojson',driver='GeoJSON')\n",
    "\n",
    "    with open(output_folder + 'selectLink.json', 'w') as json_file:\n",
    "        json.dump({'volume':json_data},json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89d07f",
   "metadata": {},
   "source": [
    "# OD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e341ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** OD shortest path ***\n"
     ]
    }
   ],
   "source": [
    "print('*** OD shortest path ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "89facb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    od_test['geometry_o'] = od_test['geometry'].apply(lambda g: Point(g.coords[:][0]))\n",
    "    od_test['geometry_d'] = od_test['geometry'].apply(lambda g: Point(g.coords[:][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0b70a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    # find nearest node with KNN. nodes are now the origin and destination.\n",
    "    od_test['geometry'] = od_test['geometry_o']\n",
    "    neigh = nearest(od_test, possible_nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    od_test['origin'] = od_test.index.map(zone_node_dict.get)\n",
    "\n",
    "    od_test['geometry'] = od_test['geometry_d']\n",
    "    neigh = nearest(od_test, possible_nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    od_test['destination'] = od_test.index.map(zone_node_dict.get)\n",
    "\n",
    "    od_test = od_test.drop(columns=['geometry_o','geometry_d','geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b004c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    o_nodes = od_test['origin'].values\n",
    "    d_nodes = od_test['destination'].values\n",
    "\n",
    "    time_mat, predecessors, node_index = simple_routing(o_nodes,d_nodes,links,weight_col='weight',return_predecessors=True)\n",
    "    reversed_index = {v: k for k, v in node_index.items()}\n",
    "\n",
    "    links_dict = links.reset_index().set_index(['a','b'])['index'].to_dict()\n",
    "\n",
    "    routes = gpd.GeoDataFrame()\n",
    "    for o,d in  enumerate(od_test['destination'].values):\n",
    "        path = get_path(predecessors, o, node_index[d])\n",
    "        path = list(zip(path[:-1], path[1:]))\n",
    "\n",
    "        path = [(reversed_index[k[0]], reversed_index[k[1]]) for k in path]\n",
    "        path = [*map(links_dict.get,path)]\n",
    "\n",
    "        route = links.loc[path]\n",
    "        route['od_name'] =  od_test.iloc[o]['name']\n",
    "        routes = pd.concat([routes,route])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65980f",
   "metadata": {},
   "source": [
    "# export OD routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "13224f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    routes.to_file(output_folder + 'od_routes.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637bbb47",
   "metadata": {},
   "source": [
    "#  kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "64c96086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KPI ***\n"
     ]
    }
   ],
   "source": [
    "print('*** KPI ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd47e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e4884f",
   "metadata": {},
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "73abdc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=[\"#559BB4\",\"#91A564\",\"#DC9100\",\"#D22328\",\"#8C4B7D\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b265bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#559BB4\",\"#91A564\",\"#DC9100\",\"#D22328\",\"#8C4B7D\",\"#A08C69\",\"#647D6E\",\"#5A7382\",\"#64411E\",\"#A00037\",\"#643C5A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "086d2ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[232], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m res \u001b[38;5;241m=\u001b[39m links\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcycleway\u001b[39m\u001b[38;5;124m'\u001b[39m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolkm\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;28msum\u001b[39m)\n\u001b[1;32m      3\u001b[0m res \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, res\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m cols \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      7\u001b[0m res\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (vol.km)\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/quetzal-77-onnKO/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No'"
     ]
    }
   ],
   "source": [
    "links['volkm'] = links['volume']*links['length']/1000\n",
    "res = links.groupby('cycleway')[['volkm']].agg(sum)\n",
    "res = res.T.fillna(0)\n",
    "res = pd.concat([res['No'], res.drop('No', axis=1)], axis=1)\n",
    "\n",
    "cols = res.columns\n",
    "res.columns = res.columns+' (vol.km)'\n",
    "volkm_cols = res.columns\n",
    "res = res.rename(index={'volkm':''})\n",
    "res.columns.name=''\n",
    "res['cycle (vol.km)'] = res.sum(axis=1)\n",
    "volpercent_cols=[]\n",
    "for col in cols:\n",
    "    volpercent_cols.append(col + ' (%vol)')\n",
    "    res[col + ' (%vol)'] = 100* res[col + ' (vol.km)'] / res['cycle (vol.km)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893313e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crow fligh\n",
    "geom_dict = add_geometry_coordinates(zones)[['y_geometry','x_geometry']].apply(tuple,axis=1).to_dict()\n",
    "demand['distance'] = demand[['o_zone','d_zone']].apply(lambda x: get_flight_distance([*map(geom_dict.get, x.values)]), axis=1)\n",
    "res['crow (vol.km)'] = sum(demand['volume'] * demand['distance'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['cycle-crow (vol.km)'] = res['cycle (vol.km)'] - res['crow (vol.km)']\n",
    "res['cycle/crow (%)'] = 100 * res['cycle (vol.km)']/ res['crow (vol.km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent of links with cycleway (no volume here)\n",
    "tmp = links.groupby('cycleway')[['length']].agg(sum)/1000\n",
    "tmp = tmp.T.fillna(0)\n",
    "tmp = pd.concat([tmp['No'], tmp.drop('No', axis=1)], axis=1)\n",
    "\n",
    "cols = tmp.columns\n",
    "\n",
    "tmp.columns = tmp.columns+' (%)'\n",
    "percent_cols = tmp.columns\n",
    "\n",
    "tmp = tmp.rename(index={'length':''})\n",
    "tmp.columns.name=''\n",
    "tot = tmp.sum(axis=1)\n",
    "for col in cols:\n",
    "    tmp[col + ' (%)'] = 100* tmp[col + ' (%)'] / tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res,tmp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97426d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(output_folder+'network_kpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "data = put_units_in_row(res)\n",
    "plot = render_mpl_table(data, header_size=12, font_size=12, row_height=0.4, col_width=1.3, index_width_ratio=1)\n",
    "title = 'Network table'\n",
    "plot.set_title(title , fontsize=12)\n",
    "file = output_folder+'6_'+'{title}.png'.format(title=normalize(title))\n",
    "plot.get_figure().savefig(file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92555b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05647b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_plot_data(df, columns, num_bar=5, keep_order=True):\n",
    "    '''\n",
    "    take a df and a list of columns in this df.\n",
    "    keep n_bar highest values agg sum the rest into 'Others'\n",
    "    keep_order will keep the original df columns order (if not. sorted highest first)\n",
    "    '''\n",
    "    col_list = df[columns].sum(axis=0).sort_values(ascending=False).index\n",
    "    cols = col_list[0:num_bar]\n",
    "    agg_cols = col_list[num_bar:]\n",
    "    if keep_order:\n",
    "        cols = [col for col in columns if col in cols]\n",
    "    \n",
    "    data = df[cols].copy()\n",
    "    data['Others'] = df[agg_cols].copy().sum(axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01639bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbe562",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bar=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bccc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c2cd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "res['crow (vol.km)'].plot(kind='barh',ax=ax, color=colors[0], position=0,width=0.4)\n",
    "data = get_agg_plot_data(res,volkm_cols,num_bar)\n",
    "data.plot(kind='barh',stacked=True, ax=ax,position=1,width=0.4,color=colors[1:])\n",
    "spacing = (ax.get_xticks()[1] - ax.get_xticks()[0])/2\n",
    "annot_position = res.iloc[0]['cycle (vol.km)'] + spacing/2\n",
    "plt.ylim([-0.5,len(res)-0.5])\n",
    "plt.xlim(ax.get_xticks()[0], annot_position+spacing)\n",
    "plt.annotate('+' + str(round(res.iloc[0]['cycle/crow (%)'])-100) + '%', xy=(annot_position,-0.18), ha='center', va='bottom',fontsize=12)\n",
    "\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for item in legend.get_texts():\n",
    "    item.set_text(item.get_text().replace(' (vol.km)', ''))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Distance (vol.km)\")\n",
    "plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "ax.set_axisbelow(True)\n",
    "#plt.gcf().axes[0].xaxis.get_major_formatter().set_scientific(False)\n",
    "ax.xaxis.set_major_formatter(lambda x,y: '{:,}'.format(int(x)).replace(',', ' '))\n",
    "\n",
    "plt.title('Total cycle distance vs as the crow flies distance')\n",
    "plt.savefig(output_folder+'1_total_distance_km.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904df939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7b7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6699c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_agg_plot_data(res, volpercent_cols, num_bar)\n",
    "ax = data.plot(kind='barh',stacked=True,figsize=(10, 4),color=colors[1:])\n",
    "\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for item in legend.get_texts():\n",
    "    item.set_text(item.get_text().replace(' (%vol)', ''))\n",
    "    \n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlim([0,105])\n",
    "plt.xlabel(\"Distance (% of vol.km)\")\n",
    "plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "ax.set_axisbelow(True)\n",
    "plt.title('Total percent of cycle distance')\n",
    "plt.savefig(output_folder+'2_total_distance_percent.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15860f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_agg_plot_data(res, percent_cols, num_bar)\n",
    "\n",
    "ax = data.plot(kind='barh',stacked=True,figsize=(10, 4),color=colors[1:])\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for item in legend.get_texts():\n",
    "    item.set_text(item.get_text().replace(' (%)', ''))\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Distance (%)\")\n",
    "plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "ax.set_axisbelow(True)\n",
    "plt.title('Percent of cycleway on the network')\n",
    "plt.savefig(output_folder+'3_percent_cycleway_network.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3947c",
   "metadata": {},
   "source": [
    "# KPI  per OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c7838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25677d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    res = routes.groupby(['od_name','cycleway'])[['length']].agg(sum)/1000\n",
    "    res = res.unstack().fillna(0)\n",
    "    res.columns = res.columns.levels[1]\n",
    "    res = pd.concat([res['No'], res.drop('No', axis=1)], axis=1)\n",
    "    cols = res.columns\n",
    "    res.columns = res.columns+' (km)'\n",
    "    km_cols = res.columns\n",
    "    res['cycle (km)'] = res.sum(axis=1)\n",
    "    tot = res['cycle (km)']\n",
    "    \n",
    "    percent_cols = []\n",
    "    for col in cols:\n",
    "        percent_cols.append(col + ' (%)')\n",
    "        res[col + ' (%)'] = 100* res[col + ' (km)'] / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    geom_dict = add_geometry_coordinates(nodes)[['y_geometry','x_geometry']].apply(tuple,axis=1).to_dict()\n",
    "    od_test['crow (km)'] = od_test[['origin','destination']].apply(lambda x: get_flight_distance([*map(geom_dict.get, x.values)]), axis=1)/1000\n",
    "    tmp_dict = od_test.set_index('name')['crow (km)'].to_dict()\n",
    "    res['crow (km)'] = res.index.map(tmp_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ccec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    res['cycle-crow (km)'] = res['cycle (km)'] - res['crow (km)']\n",
    "    res['cycle/crow (%)'] = 100 * res['cycle (km)']/ res['crow (km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    res.to_csv(output_folder+'od_kpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb654882",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    # PLOT\n",
    "    data = put_units_in_row(res)\n",
    "    plot = render_mpl_table(data, header_size=12, font_size=12, row_height=0.4, col_width=1.5, index_width_ratio=2.2)\n",
    "    title = 'OD table'\n",
    "    plot.set_title(title , fontsize=12)\n",
    "    file = output_folder+'7_'+'{title}.png'.format(title=normalize(title))\n",
    "    plot.get_figure().savefig(file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1919c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    res['crow (km)'].plot(kind='barh',ax=ax, color=colors[0], position=0, width=0.4)\n",
    "    data = get_agg_plot_data(res, km_cols, num_bar)\n",
    "    data.plot(kind='barh', stacked=True, ax=ax, position=1, width=0.4,color=colors[1:])\n",
    "\n",
    "\n",
    "    spacing = (ax.get_xticks()[1] - ax.get_xticks()[0])/2\n",
    "    annot_position = res['cycle (km)'].values + spacing/2\n",
    "    plt.ylim([-0.5,len(res)-0.5])\n",
    "    plt.xlim(ax.get_xticks()[0], max(annot_position) + spacing)\n",
    "    annot_percent = ['+'+str(round(val)-100)+'%' for val in res['cycle/crow (%)'].values]\n",
    "    for i in range(len(annot_position)):\n",
    "        plt.annotate(annot_percent[i], xy=(annot_position[i], i-0.1), ha='center', va='bottom',fontsize=10)\n",
    "\n",
    "\n",
    "    legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for item in legend.get_texts():\n",
    "        item.set_text(item.get_text().replace(' (km)', ''))\n",
    "        \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Distance (km)\")\n",
    "    plt.ylabel('Origin-Destination name')\n",
    "    plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "\n",
    "    plt.title('Cycle distance vs as the crow flies distance')\n",
    "    plt.savefig(output_folder+'4_od_distance_km.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a5a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0746680",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    data = get_agg_plot_data(res, percent_cols, num_bar)\n",
    "    ax = data.plot(kind='barh',stacked=True,figsize=(10, 10),color=colors[1:])\n",
    "    plt.legend(loc=\"upper right\", ncol=1)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Distance (%)\")\n",
    "    plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for item in legend.get_texts():\n",
    "        item.set_text(item.get_text().replace(' (%)', ''))\n",
    "        \n",
    "    plt.title('percent of distance on cycleway')\n",
    "    plt.savefig(output_folder+'5_od_distance_percent.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79c19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Finish! ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c9663",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6522ef",
   "metadata": {},
   "source": [
    "# merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "id": "228b5931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef merge_quenedi_rlinks(road_links,new_col):\\n    if 'oneway' not in road_links.columns:\\n        print('no column oneway. do not merge')\\n        return\\n    #get reversed links\\n    index_r = [idx for idx in road_links.index if idx.endswith('_r')]\\n    if len(index_r) == 0:\\n        print('all oneway, nothing to merge')\\n        return\\n    links_r = road_links.loc[index_r].copy()\\n    # create new reversed column with here speed and time\\n    links_r[new_col + '_r'] = links_r[new_col]\\n    # reindex with initial non _r index to merge\\n    links_r.index = links_r.index.map(lambda x: x[:-2])\\n    links_r = links_r[[new_col + '_r']]\\n    # drop added _r links, merge new here columns to inital two way links.\\n    road_links = road_links.drop(index_r, axis=0)\\n    # drop column if they exist before merge. dont want duplicates\\n    if new_col + '_r' in road_links.columns:\\n        road_links = road_links.drop(columns=new_col + '_r')\\n    road_links = pd.merge(road_links, links_r, left_index=True, right_index\\n                                =True, how='left')\\n    return road_links\\n\""
      ]
     },
     "execution_count": 1167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def merge_quenedi_rlinks(road_links,new_col):\n",
    "    if 'oneway' not in road_links.columns:\n",
    "        print('no column oneway. do not merge')\n",
    "        return\n",
    "    #get reversed links\n",
    "    index_r = [idx for idx in road_links.index if idx.endswith('_r')]\n",
    "    if len(index_r) == 0:\n",
    "        print('all oneway, nothing to merge')\n",
    "        return\n",
    "    links_r = road_links.loc[index_r].copy()\n",
    "    # create new reversed column with here speed and time\n",
    "    links_r[new_col + '_r'] = links_r[new_col]\n",
    "    # reindex with initial non _r index to merge\n",
    "    links_r.index = links_r.index.map(lambda x: x[:-2])\n",
    "    links_r = links_r[[new_col + '_r']]\n",
    "    # drop added _r links, merge new here columns to inital two way links.\n",
    "    road_links = road_links.drop(index_r, axis=0)\n",
    "    # drop column if they exist before merge. dont want duplicates\n",
    "    if new_col + '_r' in road_links.columns:\n",
    "        road_links = road_links.drop(columns=new_col + '_r')\n",
    "    road_links = pd.merge(road_links, links_r, left_index=True, right_index\n",
    "                                =True, how='left')\n",
    "    return road_links\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "76aa32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links = merge_quenedi_rlinks(links,'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dfe2fb",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e01c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
