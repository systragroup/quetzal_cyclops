{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "aggregation = {'distance':1000}\n",
    "constant = {'cst_incline':1}\n",
    "cycleway_weight = {\"Advisory bike lane\": 1,\n",
    "         \"Advisory bike lane (single side)\": 1,\n",
    "         \"Bicyclists dismount\": 0.2,\n",
    "         \"Bus lane with cycling allowed\": 0.8,\n",
    "         \"Buffered bike lane (road-side)\": 0.9,\n",
    "         \"Buffered bike lane (kerb-side)\": 0.9,\n",
    "         \"Buffered bike lane (both sides)\": 0.9,\n",
    "         \"Dedicated bike path\": 1,\n",
    "         \"Dedicated oneway bike path\": 1,\n",
    "         \"Future cycleway\": 0,\n",
    "         \"Future link\": 0,\n",
    "         \"Painted bike lane\": 0.8,\n",
    "         \"Peak hour bike lane\": 1,\n",
    "         \"Pedestrian path/street with cycling allowed\": 0.9,\n",
    "         \"Possible cycling infrastructure/link\": 0.5,\n",
    "         \"Protected bike lane\": 1,\n",
    "         \"Shared bike path\": 0.6,\n",
    "         \"Shared zone\": 0.6,\n",
    "         \"Sharrow\": 0.5,\n",
    "         \"Shoulder cyclable\": 0.8\n",
    "        }\n",
    "road_weight = {'residential':0.5,\n",
    "            'secondary_link':0.3,\n",
    "            'secondary':0.3,\n",
    "            'tertiary':0.3,\n",
    "            'cycleway':1.1,\n",
    "            'primary':0.3,\n",
    "            'motorway_link':0,\n",
    "            'primary_link':0.3,\n",
    "            'tertiary_link':0.3,\n",
    "            'motorway':0,\n",
    "            'trunk':0.2, \n",
    "            'trunk_link':0.2  \n",
    "            }\n",
    "\n",
    "params = {'aggregation':aggregation,'constant':constant, 'cycleway_weight': cycleway_weight, 'road_weight': road_weight}\n",
    "\n",
    "         \n",
    "\n",
    "default = {'training_folder': '../../scenarios/base', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "from quetzal.engine.road_model import RoadModel, _reverse_geom\n",
    "from quetzal.engine.pathfinder_utils import get_path, parallel_dijkstra, build_index, sparse_matrix\n",
    "from quetzal.engine.msa_utils import get_zone_index, assign_volume\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from typing import Tuple\n",
    "from geopy.distance import geodesic  # works for geopy version >=2\n",
    "#from sklearn.cluster import KMeans\n",
    "from syspy.spatial.spatial import nearest, agglomerative_clustering, voronoi_diagram_dataframes, add_geometry_coordinates\n",
    "from quetzal.engine.pathfinder_utils import simple_routing,get_path\n",
    "num_cores = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc057466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicated_links(links: gpd.GeoDataFrame,\n",
    "                          sort_column: str = 'maxspeed', \n",
    "                          ascending: bool = False, \n",
    "                          return_dropped:bool = False)-> Tuple[gpd.GeoDataFrame,list]:\n",
    "    '''\n",
    "    drop duplicated links (a,b) with condition sort_column. if maxspeed and ascending=False, keep faster road\n",
    "    '''\n",
    "    before = set(links.index)\n",
    "    links['dup'] = links['a'] + links['b']\n",
    "    links = links.sort_values(sort_column, ascending=ascending).drop_duplicates('dup').sort_index()\n",
    "    links = links.drop(columns='dup')\n",
    "    after = set(links.index)\n",
    "    diff = list(before-after)\n",
    "    print(len(diff), 'links dropped')\n",
    "    return links, diff\n",
    "\n",
    "def get_epsg(lat: float, lon: float) -> int:\n",
    "    '''\n",
    "    return EPSG in meter for a given (lat,lon)\n",
    "    lat is north south \n",
    "    lon is est west\n",
    "    '''\n",
    "    return int(32700 - round((45 + lat) / 90, 0) * 100 + round((183 + lon) / 6, 0))\n",
    "\n",
    "def zones_nearest_node(zones,nodes,drop_duplicates=False):\n",
    "    # getting zones centroids\n",
    "    centroid = zones.copy()\n",
    "    centroid['geometry'] = centroid.centroid\n",
    "    # finding nearest node\n",
    "    neigh = nearest(centroid, nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    centroid['node_index'] = centroid.index.map(zone_node_dict.get)\n",
    "    print('max_distance found: ', neigh['distance'].max())\n",
    "    # check for duplicated nodes. if there is. drop the duplicated zones.\n",
    "    if drop_duplicates:\n",
    "        if len(centroid.drop_duplicates('node_index')) != len(centroid):\n",
    "            print('there is zones associates to the same road_node')\n",
    "            # duplicated = centroid[centroid['node_index'].duplicated()]['node_index'].values\n",
    "            print('dropping zones: ')\n",
    "            print(centroid[centroid['node_index'].duplicated()].index.values)\n",
    "            centroid = centroid.drop_duplicates('node_index')\n",
    "    return centroid\n",
    "\n",
    "import math\n",
    "def haversine(coord1: object, coord2: object):\n",
    "    # Coordinates in decimal degrees (e.g. 2.89078, 12.79797)\n",
    "    lat1, lon1= coord1\n",
    "    lat2, lon2 = coord2\n",
    "\n",
    "    R = 6371000  # radius of Earth in meters\n",
    "    phi_1 = math.radians(lat1)\n",
    "    phi_2 = math.radians(lat2)\n",
    "\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2.0) ** 2 + math.cos(phi_1) * math.cos(phi_2) * math.sin(delta_lambda / 2.0) ** 2\n",
    "\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    meters = R * c  # output distance in meters\n",
    "    \n",
    "    return meters\n",
    "\n",
    "def get_flight_distance(x):\n",
    "    # inputs : [(lat,lon), (lat,lon)]. or [(y,x),(y,x)]\n",
    "    # however. geodesic use lon,lat. so its inverted here\n",
    "    # Switch for haversine as it is ~30X faster.\n",
    "\n",
    "    return haversine(x[0],x[1])\n",
    "    #return geodesic(x[0], x[1]).m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb087e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization.py\n",
    "import six\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rounding(x):\n",
    "    if type(x)==str:\n",
    "        return x\n",
    "    elif x<10:\n",
    "        return float(np.round(x,2))\n",
    "    elif x<100:\n",
    "        return float(np.round(x,1))\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def put_units_in_row(df):\n",
    "    df = df.applymap(rounding, na_action='ignore')\n",
    "    index = df.index.values\n",
    "    df.loc['units'] = [col.split(' ')[1] for col in df.columns]\n",
    "    df.columns = [col.split(' ')[0] for col in df.columns]\n",
    "    index = np.insert(index,0,'units')\n",
    "    df = df.loc[index]\n",
    "    return df\n",
    "\n",
    "def normalize(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode().replace(' ', '_').lower().replace(',', '')\n",
    "\n",
    "class Current:\n",
    "    def __init__(self):\n",
    "        self.s = ''\n",
    "        \n",
    "    def replace_seen(self, s):\n",
    "        if self.s == s:\n",
    "            to_return = ''\n",
    "        else :\n",
    "            to_return = s \n",
    "        self.s = s\n",
    "        return to_return\n",
    "\n",
    "def label_index(data):\n",
    "    ix_name = data.index.name\n",
    "    c_name = data.columns.name \n",
    "    t = data.copy()\n",
    "    if c_name is not None:\n",
    "        t.index.name = c_name\n",
    "    if ix_name is not None:\n",
    "        ix = list(data.index)\n",
    "        t = t.reindex([ix_name] + list(ix))\n",
    "        t = t.fillna('')\n",
    "    return t\n",
    "\n",
    "def render_mpl_table(\n",
    "    data, \n",
    "    col_width=3.0, \n",
    "    row_height=0.625, \n",
    "    font_size=14,\n",
    "    header_size=14,\n",
    "    index_width_ratio=2,\n",
    "    header_color='#9d1a1e', \n",
    "    header_font_color = 'w',\n",
    "    sub_header_color='#d22328',\n",
    "    row_colors=['#f1f1f2', 'w'], \n",
    "    edge_color='w',\n",
    "    index_edge_color='#9d1a1e',\n",
    "    bbox=[0, 0, 1, 1], \n",
    "    header_columns=0,\n",
    "    figsize=None,\n",
    "    ax=None, \n",
    "    dpi=96,\n",
    "    **kwargs\n",
    "):\n",
    "    #c_levels = len(data.columns.names)\n",
    "    #c_first = data.columns.names[0]\n",
    "    \n",
    "    \n",
    "    i_levels = len(data.index.names)\n",
    "    i_first = list(data.index.names)[0]\n",
    "\n",
    "    data = data.reset_index()\n",
    "    current = Current()\n",
    "    try:\n",
    "        data[i_first] = data[i_first].apply(lambda s: current.replace_seen(s))\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    if figsize:\n",
    "        col_width = figsize[0] / (len(data.T) + (index_width_ratio - 1))\n",
    "        row_height = figsize[1] / (len(data) +1)\n",
    "        \n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size, dpi=dpi)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    \n",
    "\n",
    "    mpl_table = ax.table(\n",
    "        cellText=data.values, \n",
    "        bbox=bbox, \n",
    "        colLabels=data.columns, \n",
    "        colWidths= [col_width * index_width_ratio ] + [col_width for c in data.columns[1:]],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "    for k, cell in  six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(index_edge_color)\n",
    "        if k[0] < 1 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color=header_font_color)\n",
    "\n",
    "            cell.set_text_props( color=header_font_color)\n",
    "            cell.set_fontsize(header_size)\n",
    "            cell.set_facecolor(header_color)\n",
    "\n",
    "        elif k[1] < i_levels:\n",
    "            cell.set_text_props(weight='bold', color=header_font_color)\n",
    "            cell.set_text_props( color=header_font_color)\n",
    "            cell.set_fontsize(header_size)\n",
    "            cell.set_facecolor(sub_header_color)\n",
    "        else:\n",
    "            cell.set_edgecolor(edge_color)\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_engine = 'pyogrio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e405b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = argv['training_folder']\n",
    "input_folder = os.path.join(base_folder,'inputs/')\n",
    "road_folder = os.path.join(input_folder,'road/')\n",
    "od_folder =  os.path.join(input_folder,'od/')\n",
    "demand_folder = input_folder\n",
    "\n",
    "output_folder = os.path.join(base_folder,'outputs/')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd032bd",
   "metadata": {},
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_incline = argv['params' ]['constant']['cst_incline']\n",
    "cst_road = argv['params']['road_weight']\n",
    "cst_road = {k:float(v) for k,v in cst_road.items()}\n",
    "cst_cycleway = argv['params']['cycleway_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure its float\n",
    "cst_incline = float(cst_incline)\n",
    "cst_cycleway = {k:float(v) for k,v in cst_cycleway.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b20ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a674100",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(road_folder + 'road_links.geojson', engine=io_engine) \n",
    "nodes = gpd.read_file(road_folder + 'road_nodes.geojson', engine=io_engine)\n",
    "links = links.set_index('index')\n",
    "nodes = nodes.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepath(path,filename):\n",
    "    '''\n",
    "    get filePath cas insensitive (ex: read demand.csv but file is name DEMAND.csv)\n",
    "    path:'path/ ex: '../../scenarios/base/inputs/'\n",
    "    filename: ex: demand.csv\n",
    "    '''\n",
    "    files = os.listdir(demand_folder)\n",
    "    file = [file for file in files if filename.lower() == file.lower()]\n",
    "    if len(file)==0:\n",
    "        print(f'{path+filename} does not exist')\n",
    "        return path+filename\n",
    "    return path+file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_file = get_filepath(demand_folder ,'demand.csv')\n",
    "demand_provided = os.path.isfile(demand_file)\n",
    "if demand_provided:\n",
    "    demand = pd.read_csv(demand_file)\n",
    "    assert all([col in demand.columns for col in ['lon_ori','lat_ori','lon_des','lat_des','volume'] ]), 'need lon_ori, lat_ori, lon_des, lat_des, volume in demand'\n",
    "    demand = demand[['lon_ori','lat_ori','lon_des','lat_des','volume']]\n",
    "else: #mock it\n",
    "    from shapely.geometry import Point, LineString\n",
    "    centroid = [*LineString(nodes.centroid.values).centroid.coords][0]\n",
    "    demand = pd.DataFrame(data={'lon_ori':centroid[0],'lat_ori':centroid[1],'lon_des':centroid[0],'lat_des':centroid[1],'volume':0},index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37b750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a66bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c9feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_file = od_folder + 'od.geojson'\n",
    "od_file_provided = os.path.isfile(od_file)\n",
    "if od_file_provided:\n",
    "    od_test = gpd.read_file(od_folder + 'od.geojson', engine=io_engine)\n",
    "    if 'name' not in od_test.columns:\n",
    "        od_test['name'] = od_test['index']\n",
    "    od_test['name'] = od_test['name'].fillna(od_test['index'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e31338",
   "metadata": {},
   "source": [
    "# agg demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fe77d",
   "metadata": {},
   "source": [
    "format demand and create zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e83de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Demand Aggregation ***')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b25b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['origin'] = [*zip(demand['lon_ori'],demand['lat_ori'])]\n",
    "demand['destination'] = [*zip(demand['lon_des'],demand['lat_des'])]\n",
    "demand = demand.drop(columns=['lat_ori','lon_ori','lat_des','lon_des'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique zones\n",
    "zones_set = set(demand['origin'].values).union(set(demand['destination'].values))\n",
    "zones_dict = {val:'zone_'+str(i) for i,val in enumerate(zones_set)}\n",
    "zones_df = [{'index':zone,'geometry':Point(val)} for val,zone in zones_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['origin'] = demand['origin'].apply(lambda x: zones_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: zones_dict.get(x))\n",
    "zones = gpd.GeoDataFrame(zones_df,crs=4326).set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cddac1",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de080e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dist = float(argv['params']['aggregation']['distance'])\n",
    "epsg = get_epsg(zones.iloc[0]['geometry'].y, zones.iloc[0]['geometry'].x)\n",
    "## cannot agg 1 zones. this happens when no demand is provided with mock demand.\n",
    "if len(zones)>1:\n",
    "    label = agglomerative_clustering(zones.to_crs(epsg), distance_threshold = agg_dist)\n",
    "    zones['cluster'] = label\n",
    "else: \n",
    "    zones['cluster'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(zones),'zones agg to',len(zones['cluster'].unique()),' zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict zone:cluster\n",
    "zones['cluster'] = 'zone_' + zones['cluster'].astype(str)\n",
    "cluster_dict = zones['cluster'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated cluster and rename index with new cluster as zones_id\n",
    "zones = zones.drop_duplicates('cluster')\n",
    "zones = zones.set_index('cluster')\n",
    "zones.index.name='index'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d3cdc",
   "metadata": {},
   "source": [
    " AGG demand on new zones (volime is sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677503c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply new cluster fict to the demand\n",
    "demand['origin'] = demand['origin'].apply(lambda x: cluster_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: cluster_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = demand.groupby(['origin','destination']).agg('sum').reset_index()\n",
    "demand.index.name = 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c692d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18fa6f20",
   "metadata": {},
   "source": [
    "# export zones and demand in outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zones.to_file(output_folder + 'centroids.geojson',driver='GeoJSON')\n",
    "print('*** Creating and exporting zones ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcea6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_func(x):\n",
    "    return dict(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef791144",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data={}\n",
    "\n",
    "grouped = demand.groupby([\"origin\", \"destination\"])[\"volume\"].sum().reset_index()\n",
    "grouped['outgoing volume'] = list(zip(grouped['destination'],grouped['volume']))\n",
    "data = grouped.groupby('origin').agg({'outgoing volume':agg_func}).to_dict()\n",
    "json_data.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42977c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = demand.groupby([\"destination\", \"origin\"])[\"volume\"].sum().reset_index()\n",
    "grouped['ingoing volume'] = list(zip(grouped['origin'],grouped['volume']))\n",
    "data = grouped.groupby('destination').agg({'ingoing volume':agg_func}).to_dict()\n",
    "json_data.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(demand)>1: # if demand is provided.    \n",
    "    with open(output_folder + 'zones.json', 'w') as json_file:\n",
    "        json.dump(json_data,json_file)\n",
    "    with open(output_folder + 'demand.json', 'w') as json_file:\n",
    "        json.dump(json_data,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1526ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "production = demand.groupby([\"origin\"])[\"volume\"].sum().to_dict()\n",
    "attraction = demand.groupby([\"destination\"])[\"volume\"].sum().to_dict()\n",
    "zones['production'] = zones.index.map(production.get)\n",
    "zones['attraction'] = zones.index.map(attraction.get)\n",
    "zones = zones.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a155181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(zones) > 1: #dont do it if demand is not provided\n",
    "    convex_hull = zones.union_all().convex_hull.buffer(1e-3)\n",
    "    voronoi, _ = voronoi_diagram_dataframes(zones['geometry'])\n",
    "    voronoi.crs = 4326\n",
    "    \n",
    "    voronoi = pd.merge(voronoi,zones[['production','attraction']],left_index=True,right_index=True)\n",
    "    voronoi = voronoi.clip(convex_hull)\n",
    "    \n",
    "    voronoi.to_file(output_folder + 'zones.geojson',driver='GeoJSON', engine=io_engine)\n",
    "    zones.to_file(output_folder + 'demand.geojson',driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd6c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def create_zones_from_nodes(nodes,num_zones=200):\n",
    "    nodes['x'] = nodes['geometry'].apply(lambda p:p.x)\n",
    "    nodes['y'] = nodes['geometry'].apply(lambda p:p.y)\n",
    "    cluster = KMeans(n_clusters=num_zones,random_state=0,n_init='auto')\n",
    "    cluster.fit(nodes[['x','y']].values)\n",
    "    geom = [Point(val) for val in cluster.cluster_centers_]\n",
    "    zones = gpd.GeoDataFrame(range(len(geom)),geometry=geom,crs=4326).drop(columns=0)\n",
    "    zones.index = 'zone_' + zones.index.astype(str)\n",
    "    return zones\n",
    "#create_zones_from_nodes(zones).plot()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82be5c4",
   "metadata": {},
   "source": [
    "# split oneway quenedi links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ce6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Processing cycleways ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split quenedi road links\n",
    "self = RoadModel(links,nodes,zones,ff_time_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae842aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('split rlinks to oneways')\n",
    "self.split_quenedi_rlinks()\n",
    "#self.zones_nearest_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = self.road_links\n",
    "del self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ffc54",
   "metadata": {},
   "source": [
    "# tag cycleways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c79545",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [idx for idx in links.index if not idx.endswith('_r')]\n",
    "index_r = [idx for idx in links.index if idx.endswith('_r')]\n",
    "assert len(index)+len(index_r) == len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted links cycleway is the reverse one\n",
    "links.loc[index_r,'cycleway'] = links.loc[index_r,'cycleway_reverse'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1035c",
   "metadata": {},
   "source": [
    "split oneway road with cycleway on both side or only in reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245dae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_quenedi_cycleway(links, oneway='1',no_col='No'):\n",
    "    # add oneway links with cycleway_reverse as links. only the one with cycleway_reverse != No.\n",
    "    # so. you can cycle on oneway with no cycleway only in the oneway direction.\n",
    "    if 'oneway' not in links.columns:\n",
    "        print('no column oneway. do not split')\n",
    "        return\n",
    "    links_c = links[links['oneway']==oneway].copy()\n",
    "    if len(links_c) == 0:\n",
    "        print('all oneway, nothing to split')\n",
    "    \n",
    "    links_c = links_c[links_c['cycleway_reverse'] != no_col]\n",
    "    links_c['cycleway'] = links_c['cycleway_reverse']\n",
    "    links_c.index = links_c.index.astype(str) + '_c'\n",
    "    \n",
    "    # reverse links (a=>b, b=>a)\n",
    "    links_c = links_c.rename(columns={'a': 'b', 'b': 'a'})\n",
    "    links_c['geometry'] = links_c['geometry'].apply(lambda g: _reverse_geom(g))\n",
    "    links = pd.concat([links, links_c])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = split_quenedi_cycleway(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_c = [idx for idx in links.index if idx.endswith('_c')]\n",
    "assert len(index)+len(index_r)+len(index_c) == len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = [col for col in links.columns if col.endswith('_r')]\n",
    "if 'cycleway_reverse' in links.columns:\n",
    "    r_cols = r_cols + ['cycleway_reverse']\n",
    "links = links.drop(columns=r_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88338a7e",
   "metadata": {},
   "source": [
    "# inclines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534437c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['incline'] = links['incline'].astype(float)\n",
    "links['incline'] = links['incline'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse incline on reversed links\n",
    "links.loc[index_r,'incline'] = -links.loc[index_r,'incline']\n",
    "#create this column for vizualisation\n",
    "links['incline (abs)'] = abs(links['incline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0830f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5588921e",
   "metadata": {},
   "source": [
    "# apply Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e3281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incline weigth (starting point)\n",
    "default_speed = 20 #kmh\n",
    "links['eff_speed'] = default_speed   * (1 - cst_incline * np.sin(np.deg2rad(links['incline'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['cst_road'] = links['highway'].apply(lambda x: cst_road.get(x,1))\n",
    "links['cst_cycleway'] = links['cycleway'].apply(lambda x: cst_cycleway.get(x,np.nan))\n",
    "links['cst'] = links['cst_cycleway'].combine_first(links['cst_road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5567729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93500c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derate it with cycleway\n",
    "links['eff_speed'] = links['eff_speed'] * links['cst']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b554b1c",
   "metadata": {},
   "source": [
    "transform effective speed to a weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anything with neg speed round to 0. (dijkstra need positive weight)\n",
    "links['eff_speed'] = links['eff_speed'].apply(lambda x : max(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['weight'] = links['length']/(links['eff_speed']*1000/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e71f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.drop(columns=['cst_cycleway','cst_road','cst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac74cfc",
   "metadata": {},
   "source": [
    "# zone to nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfd282",
   "metadata": {},
   "source": [
    "get the list of nodes with weight != inf. we do not want to route from or to nodes that are not cycle (ex motorway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Zones to nodes ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlinks = links[np.isfinite(links['weight'])][['a','b']]\n",
    "nodes_set = set(tlinks['a']).union(set(tlinks['b']))\n",
    "possible_nodes = nodes.loc[list(nodes_set)].sort_index()\n",
    "del tlinks,nodes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = zones_nearest_node(zones, possible_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb00df2",
   "metadata": {},
   "source": [
    "# Shortest path + volume assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ece518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Assigning volume ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51bbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_nodes_dict = zones['node_index'].to_dict()\n",
    "demand['o_zone'] = demand['origin']\n",
    "demand['d_zone'] = demand['destination']\n",
    "demand['origin'] = demand['origin'].apply(lambda x: zones_nodes_dict.get(x))\n",
    "demand['destination'] = demand['destination'].apply(lambda x: zones_nodes_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47785fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = links[['a', 'b','weight']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b18c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dropped = drop_duplicated_links(df,sort_column='weight',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43aecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df[['a', 'b', 'weight']].values  # to build the index once and for all\n",
    "index = build_index(edges)\n",
    "reversed_index = {v: k for k, v in index.items()}\n",
    "# apply sparse index on zones\n",
    "demand, zones_indices = get_zone_index(df, demand, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484da8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sparse index on links\n",
    "df['sparse_a'] = df['a'].apply(lambda x: index.get(x))\n",
    "df['sparse_b'] = df['b'].apply(lambda x: index.get(x))\n",
    "volumes_sparse_keys = list(zip(df['sparse_a'],df['sparse_b']))\n",
    "\n",
    "odv = demand[['o', 'd', 'volume']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df[['a', 'b', 'weight']].values\n",
    "sparse, _ = sparse_matrix(edges, index=index)\n",
    "time_matrix, predecessors = parallel_dijkstra(sparse,\n",
    "                                              directed=True,\n",
    "                                              indices=zones_indices,\n",
    "                                              return_predecessors=True,\n",
    "                                              num_core=num_cores,\n",
    "                                              keep_running=True)\n",
    "\n",
    "# this give OD_time/time_matrix on each links. then X links time for the ratio links_time/tot_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40870a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_volumes = assign_volume(odv,predecessors,volumes_sparse_keys,reversed_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f67f3",
   "metadata": {},
   "source": [
    "restrict links to df.index (dropped duplicated links). if not. volume will not be assign on the right link (when duplicated) or, maybe on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36fde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['volume'] = 0.\n",
    "links.loc[df.index,'volume'] = links.loc[df.index].set_index(['a', 'b']).index.map(ab_volumes.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28babea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#volume(1/eff_speed - 1/default_speed)\n",
    "links['time_loss'] = links['volume']* (1/links['eff_speed'] - 1/default_speed)\n",
    "links.loc[~np.isfinite(links['time_loss']),'time_loss'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852143c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f993c76",
   "metadata": {},
   "source": [
    "# exporting loaded Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Exporting loaded Links ***')\n",
    "links[['highway','cycleway', 'incline (abs)', 'eff_speed','weight','volume','time_loss','geometry']].to_file(output_folder + 'loaded_links.geojson',driver='GeoJSON', engine=io_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08d87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5be1612",
   "metadata": {},
   "source": [
    "# Links Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abea006",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_list=[]\n",
    "if 'selectLink' in links.columns:\n",
    "    links_list += list(links[links['selectLink']=='yes'].index)\n",
    "if 'selectLink_reverse' in links.columns:\n",
    "    links_list += list(links[links['selectLink_reverse']=='yes'].index)\n",
    "if len(links_list)>500:\n",
    "    print('too many selectLink. keep first 500.')\n",
    "    links_list = links_list[:500]\n",
    "    \n",
    "if len(links_list) > 0:\n",
    "    links_dict = links.reset_index().set_index(['a','b'])['index'].to_dict()\n",
    "    json_data={}\n",
    "    for link in links_list:\n",
    "        volumes={}\n",
    "        for o,d,v in odv:\n",
    "            path = get_path(predecessors,o,d)\n",
    "            path = [*map(reversed_index.get, path)]\n",
    "            path = list(zip(path[:-1], path[1:]))\n",
    "            path = [*map(links_dict.get,path)]\n",
    "            if link in path:\n",
    "                for key in path:\n",
    "                    try:\n",
    "                        volumes[key] += v\n",
    "                    except KeyError:\n",
    "                        volumes[key] = v\n",
    "        if len(volumes)>0:\n",
    "            json_data[link] = volumes\n",
    "\n",
    "\n",
    "    index_set=set()\n",
    "    for key,item in json_data.items():\n",
    "        index_set.update(item.keys())\n",
    "\n",
    "    route = links.loc[list(index_set)][['geometry']]\n",
    "    route.to_file(output_folder + 'selectLink.geojson',driver='GeoJSON', engine=io_engine)\n",
    "\n",
    "    with open(output_folder + 'selectLink.json', 'w') as json_file:\n",
    "        json.dump({'volume':json_data},json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89d07f",
   "metadata": {},
   "source": [
    "# OD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** OD shortest path ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89facb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    od_test['geometry_o'] = od_test['geometry'].apply(lambda g: Point(g.coords[:][0]))\n",
    "    od_test['geometry_d'] = od_test['geometry'].apply(lambda g: Point(g.coords[:][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    # find nearest node with KNN. nodes are now the origin and destination.\n",
    "    od_test['geometry'] = od_test['geometry_o']\n",
    "    neigh = nearest(od_test, possible_nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    od_test['origin'] = od_test.index.map(zone_node_dict.get)\n",
    "\n",
    "    od_test['geometry'] = od_test['geometry_d']\n",
    "    neigh = nearest(od_test, possible_nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    od_test['destination'] = od_test.index.map(zone_node_dict.get)\n",
    "\n",
    "    od_test = od_test.drop(columns=['geometry_o','geometry_d','geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    o_nodes = od_test['origin'].values\n",
    "    d_nodes = od_test['destination'].values\n",
    "\n",
    "    time_mat, predecessors, node_index = simple_routing(o_nodes,d_nodes,links,weight_col='weight',return_predecessors=True)\n",
    "    reversed_index = {v: k for k, v in node_index.items()}\n",
    "\n",
    "    links_dict = links.reset_index().set_index(['a','b'])['index'].to_dict()\n",
    "\n",
    "    routes = gpd.GeoDataFrame()\n",
    "    for o,d in  enumerate(od_test['destination'].values):\n",
    "        path = get_path(predecessors, o, node_index[d])\n",
    "        path = list(zip(path[:-1], path[1:]))\n",
    "\n",
    "        path = [(reversed_index[k[0]], reversed_index[k[1]]) for k in path]\n",
    "        path = [*map(links_dict.get,path)]\n",
    "\n",
    "        route = links.loc[path]\n",
    "        route['od_name'] =  od_test.iloc[o]['name']\n",
    "        routes = pd.concat([routes,route])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65980f",
   "metadata": {},
   "source": [
    "# export OD routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13224f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    routes.to_file(output_folder + 'od_routes.geojson',driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637bbb47",
   "metadata": {},
   "source": [
    "#  kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c96086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** KPI ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd47e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e4884f",
   "metadata": {},
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abdc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=[\"#559BB4\",\"#91A564\",\"#DC9100\",\"#D22328\",\"#8C4B7D\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#559BB4\",\"#91A564\",\"#DC9100\",\"#D22328\",\"#8C4B7D\",\"#A08C69\",\"#647D6E\",\"#5A7382\",\"#64411E\",\"#A00037\",\"#643C5A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['volkm'] = links['volume']*links['length']/1000\n",
    "res = links.groupby('cycleway')[['volkm']].agg(sum)\n",
    "res = res.T.fillna(0)\n",
    "res = pd.concat([res['No'], res.drop('No', axis=1)], axis=1)\n",
    "\n",
    "cols = res.columns\n",
    "res.columns = res.columns+' (vol.km)'\n",
    "volkm_cols = res.columns\n",
    "res = res.rename(index={'volkm':''})\n",
    "res.columns.name=''\n",
    "res['cycle (vol.km)'] = res.sum(axis=1)\n",
    "volpercent_cols=[]\n",
    "for col in cols:\n",
    "    volpercent_cols.append(col + ' (%vol)')\n",
    "    res[col + ' (%vol)'] = 100* res[col + ' (vol.km)'] / res['cycle (vol.km)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893313e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crow fligh\n",
    "geom_dict = add_geometry_coordinates(zones)[['y_geometry','x_geometry']].apply(tuple,axis=1).to_dict()\n",
    "demand['distance'] = demand[['o_zone','d_zone']].apply(lambda x: get_flight_distance([*map(geom_dict.get, x.values)]), axis=1)\n",
    "res['crow (vol.km)'] = sum(demand['volume'] * demand['distance'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['cycle-crow (vol.km)'] = res['cycle (vol.km)'] - res['crow (vol.km)']\n",
    "res['cycle/crow (%)'] = 100 * res['cycle (vol.km)']/ res['crow (vol.km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent of links with cycleway (no volume here)\n",
    "tmp = links.groupby('cycleway')[['length']].agg(sum)/1000\n",
    "tmp = tmp.T.fillna(0)\n",
    "tmp = pd.concat([tmp['No'], tmp.drop('No', axis=1)], axis=1)\n",
    "\n",
    "cols = tmp.columns\n",
    "\n",
    "tmp.columns = tmp.columns+' (%)'\n",
    "percent_cols = tmp.columns\n",
    "\n",
    "tmp = tmp.rename(index={'length':''})\n",
    "tmp.columns.name=''\n",
    "tot = tmp.sum(axis=1)\n",
    "for col in cols:\n",
    "    tmp[col + ' (%)'] = 100* tmp[col + ' (%)'] / tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res,tmp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97426d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(output_folder+'network_kpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "data = put_units_in_row(res)\n",
    "plot = render_mpl_table(data, header_size=12, font_size=12, row_height=0.4, col_width=1.3, index_width_ratio=1)\n",
    "title = 'Network table'\n",
    "plot.set_title(title , fontsize=12)\n",
    "file = output_folder+'6_'+'{title}.png'.format(title=normalize(title))\n",
    "plot.get_figure().savefig(file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92555b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05647b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_plot_data(df, columns, num_bar=5, keep_order=True):\n",
    "    '''\n",
    "    take a df and a list of columns in this df.\n",
    "    keep n_bar highest values agg sum the rest into 'Others'\n",
    "    keep_order will keep the original df columns order (if not. sorted highest first)\n",
    "    '''\n",
    "    col_list = df[columns].sum(axis=0).sort_values(ascending=False).index\n",
    "    cols = col_list[0:num_bar]\n",
    "    agg_cols = col_list[num_bar:]\n",
    "    if keep_order:\n",
    "        cols = [col for col in columns if col in cols]\n",
    "    \n",
    "    data = df[cols].copy()\n",
    "    data['Others'] = df[agg_cols].copy().sum(axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01639bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbe562",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bar=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bccc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "res['crow (vol.km)'].plot(kind='barh',ax=ax, color=colors[0], position=0,width=0.4)\n",
    "data = get_agg_plot_data(res,volkm_cols,num_bar)\n",
    "data.plot(kind='barh',stacked=True, ax=ax,position=1,width=0.4,color=colors[1:])\n",
    "spacing = (ax.get_xticks()[1] - ax.get_xticks()[0])/2\n",
    "annot_position = res.iloc[0]['cycle (vol.km)'] + spacing/2\n",
    "plt.ylim([-0.5,len(res)-0.5])\n",
    "plt.xlim(ax.get_xticks()[0], annot_position+spacing)\n",
    "plt.annotate('+' + str(np.round(res.iloc[0]['cycle/crow (%)'])-100) + '%', xy=(annot_position,-0.18), ha='center', va='bottom',fontsize=12)\n",
    "\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for item in legend.get_texts():\n",
    "    item.set_text(item.get_text().replace(' (vol.km)', ''))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Distance (vol.km)\")\n",
    "plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "ax.set_axisbelow(True)\n",
    "#plt.gcf().axes[0].xaxis.get_major_formatter().set_scientific(False)\n",
    "ax.xaxis.set_major_formatter(lambda x,y: '{:,}'.format(int(x)).replace(',', ' '))\n",
    "\n",
    "plt.title('Total cycle distance vs as the crow flies distance')\n",
    "plt.savefig(output_folder+'1_total_distance_km.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904df939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7b7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6699c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_agg_plot_data(res, volpercent_cols, num_bar)\n",
    "ax = data.plot(kind='barh',stacked=True,figsize=(10, 4),color=colors[1:])\n",
    "\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for item in legend.get_texts():\n",
    "    item.set_text(item.get_text().replace(' (%vol)', ''))\n",
    "    \n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlim([0,105])\n",
    "plt.xlabel(\"Distance (% of vol.km)\")\n",
    "plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "ax.set_axisbelow(True)\n",
    "plt.title('Total percent of cycle distance')\n",
    "plt.savefig(output_folder+'2_total_distance_percent.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15860f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_agg_plot_data(res, percent_cols, num_bar)\n",
    "\n",
    "ax = data.plot(kind='barh',stacked=True,figsize=(10, 4),color=colors[1:])\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for item in legend.get_texts():\n",
    "    item.set_text(item.get_text().replace(' (%)', ''))\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Distance (%)\")\n",
    "plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "ax.set_axisbelow(True)\n",
    "plt.title('Percent of cycleway on the network')\n",
    "plt.savefig(output_folder+'3_percent_cycleway_network.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3947c",
   "metadata": {},
   "source": [
    "# KPI  per OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c7838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25677d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    res = routes.groupby(['od_name','cycleway'])[['length']].agg(sum)/1000\n",
    "    res = res.unstack().fillna(0)\n",
    "    res.columns = res.columns.levels[1]\n",
    "    res = pd.concat([res['No'], res.drop('No', axis=1)], axis=1)\n",
    "    cols = res.columns\n",
    "    res.columns = res.columns+' (km)'\n",
    "    km_cols = res.columns\n",
    "    res['cycle (km)'] = res.sum(axis=1)\n",
    "    tot = res['cycle (km)']\n",
    "    \n",
    "    percent_cols = []\n",
    "    for col in cols:\n",
    "        percent_cols.append(col + ' (%)')\n",
    "        res[col + ' (%)'] = 100* res[col + ' (km)'] / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    geom_dict = add_geometry_coordinates(nodes)[['y_geometry','x_geometry']].apply(tuple,axis=1).to_dict()\n",
    "    od_test['crow (km)'] = od_test[['origin','destination']].apply(lambda x: get_flight_distance([*map(geom_dict.get, x.values)]), axis=1)/1000\n",
    "    tmp_dict = od_test.set_index('name')['crow (km)'].to_dict()\n",
    "    res['crow (km)'] = res.index.map(tmp_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ccec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    res['cycle-crow (km)'] = res['cycle (km)'] - res['crow (km)']\n",
    "    res['cycle/crow (%)'] = 100 * res['cycle (km)']/ res['crow (km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    res.to_csv(output_folder+'od_kpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb654882",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    # PLOT\n",
    "    data = put_units_in_row(res)\n",
    "    plot = render_mpl_table(data, header_size=12, font_size=12, row_height=0.4, col_width=1.5, index_width_ratio=2.2)\n",
    "    title = 'OD table'\n",
    "    plot.set_title(title , fontsize=12)\n",
    "    file = output_folder+'7_'+'{title}.png'.format(title=normalize(title))\n",
    "    plot.get_figure().savefig(file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1919c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    res['crow (km)'].plot(kind='barh',ax=ax, color=colors[0], position=0, width=0.4)\n",
    "    data = get_agg_plot_data(res, km_cols, num_bar)\n",
    "    data.plot(kind='barh', stacked=True, ax=ax, position=1, width=0.4,color=colors[1:])\n",
    "\n",
    "\n",
    "    spacing = (ax.get_xticks()[1] - ax.get_xticks()[0])/2\n",
    "    annot_position = res['cycle (km)'].values + spacing/2\n",
    "    plt.ylim([-0.5,len(res)-0.5])\n",
    "    plt.xlim(ax.get_xticks()[0], max(annot_position) + spacing)\n",
    "    annot_percent = ['+'+str(np.round(val)-100)+'%' for val in res['cycle/crow (%)'].values]\n",
    "    for i in range(len(annot_position)):\n",
    "        plt.annotate(annot_percent[i], xy=(annot_position[i], i-0.1), ha='center', va='bottom',fontsize=10)\n",
    "\n",
    "\n",
    "    legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for item in legend.get_texts():\n",
    "        item.set_text(item.get_text().replace(' (km)', ''))\n",
    "        \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Distance (km)\")\n",
    "    plt.ylabel('Origin-Destination name')\n",
    "    plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "\n",
    "    plt.title('Cycle distance vs as the crow flies distance')\n",
    "    plt.savefig(output_folder+'4_od_distance_km.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a5a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0746680",
   "metadata": {},
   "outputs": [],
   "source": [
    "if od_file_provided:\n",
    "    data = get_agg_plot_data(res, percent_cols, num_bar)\n",
    "    ax = data.plot(kind='barh',stacked=True,figsize=(10, 10),color=colors[1:])\n",
    "    plt.legend(loc=\"upper right\", ncol=1)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Distance (%)\")\n",
    "    plt.grid(True, 'major', linestyle='-', axis='both')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for item in legend.get_texts():\n",
    "        item.set_text(item.get_text().replace(' (%)', ''))\n",
    "        \n",
    "    plt.title('percent of distance on cycleway')\n",
    "    plt.savefig(output_folder+'5_od_distance_percent.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79c19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Finish! ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c9663",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6522ef",
   "metadata": {},
   "source": [
    "# merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def merge_quenedi_rlinks(road_links,new_col):\n",
    "    if 'oneway' not in road_links.columns:\n",
    "        print('no column oneway. do not merge')\n",
    "        return\n",
    "    #get reversed links\n",
    "    index_r = [idx for idx in road_links.index if idx.endswith('_r')]\n",
    "    if len(index_r) == 0:\n",
    "        print('all oneway, nothing to merge')\n",
    "        return\n",
    "    links_r = road_links.loc[index_r].copy()\n",
    "    # create new reversed column with here speed and time\n",
    "    links_r[new_col + '_r'] = links_r[new_col]\n",
    "    # reindex with initial non _r index to merge\n",
    "    links_r.index = links_r.index.map(lambda x: x[:-2])\n",
    "    links_r = links_r[[new_col + '_r']]\n",
    "    # drop added _r links, merge new here columns to inital two way links.\n",
    "    road_links = road_links.drop(index_r, axis=0)\n",
    "    # drop column if they exist before merge. dont want duplicates\n",
    "    if new_col + '_r' in road_links.columns:\n",
    "        road_links = road_links.drop(columns=new_col + '_r')\n",
    "    road_links = pd.merge(road_links, links_r, left_index=True, right_index\n",
    "                                =True, how='left')\n",
    "    return road_links\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links = merge_quenedi_rlinks(links,'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dfe2fb",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e01c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76092eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed54b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
